

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>8. Rewards &mdash; Sinergym  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/doc_theme.css?v=23b407c1" />
      <link rel="stylesheet" type="text/css" href="../_static/github_style.css?v=0a3c596a" />

  
    <link rel="shortcut icon" href="../_static/logo-sidebar.png"/>
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="9. Controllers" href="controllers.html" />
    <link rel="prev" title="7. Environments Configuration and Registration" href="environments_registration.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #a5beba" >

          
          
          <a href="../index.html" class="icon icon-home">
            Sinergym
              <img src="../_static/logo-sidebar.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
  
              <p class="caption" role="heading"><span class="caption-text">Start Here</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">1. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage-example.html">2. Usage Example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">sinergym</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="buildings.html">3. Buildings</a></li>
<li class="toctree-l1"><a class="reference internal" href="weathers.html">4. Weathers</a></li>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">5. Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="environments.html">6. Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="environments_registration.html">7. Environments Configuration and Registration</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">8. Rewards</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#reward-terms">8.1. Reward terms</a></li>
<li class="toctree-l2"><a class="reference internal" href="#custom-rewards">8.2. Custom Rewards</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="controllers.html">9. Controllers</a></li>
<li class="toctree-l1"><a class="reference internal" href="wrappers.html">10. Wrappers</a></li>
<li class="toctree-l1"><a class="reference internal" href="extra-configuration.html">11. Extra Configuration in Sinergym simulations</a></li>
<li class="toctree-l1"><a class="reference internal" href="output.html">12. Output format</a></li>
<li class="toctree-l1"><a class="reference internal" href="deep-reinforcement-learning.html">13. Deep Reinforcement Learning Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="gcloudAPI.html">14. Sinergym with Google Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="github-actions.html">15. Github Actions</a></li>
<li class="toctree-l1"><a class="reference internal" href="tests.html">16. Tests</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notebooks/basic_example.html">17. Basic example</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/getting_env_information.html">18. Getting information about Sinergym environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/change_environment.html">19. Changing an environment registered in Sinergym</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/default_building_control.html">20. Default building control setting up an empty action interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/wrappers_examples.html">21. Wrappers example</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/personalize_loggerwrapper.html">22. Logger Wrapper personalization/configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/rule_controller_example.html">23. Rule Controller example</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/drl.html">24. DRL usage example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="API-reference.html">API reference</a></li>
</ul>

  <div class="sidebar-block github-block">
    <h3><i class="fa fa-github"></i> GitHub</h3>
    <ul class="simple">
      <li><a href="https://github.com/ugr-sail/sinergym" target="_blank">
        <i class="fa fa-book"></i> Repository
      </a></li>
      <li><a href="https://github.com/ugr-sail/sinergym/issues" target="_blank">üêû Issues</a></li>
      <li><a href="https://github.com/ugr-sail/sinergym/releases" target="_blank">üöÄ Releases</a></li>
    </ul>
  </div>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #a5beba" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Sinergym</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active"><span class="section-number">8. </span>Rewards</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/ugr-sail/sinergym/blob/main/docs/source/pages/rewards.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="rewards">
<h1><span class="section-number">8. </span>Rewards<a class="headerlink" href="#rewards" title="Link to this heading">ÔÉÅ</a></h1>
<p>Defining a reward function is essential in reinforcement learning. As such, <em>Sinergym</em>
provides the option to use pre-implemented reward functions or define custom ones
(refer to the section below).</p>
<p><em>Sinergym</em>‚Äôs predefined reward functions are designed as <strong>multi-objective</strong>, incorporating
both <em>energy consumption</em> and <em>thermal discomfort</em>. These are normalized and combined with
varying weights. These rewards are <strong>always negative</strong>, signifying that optimal behavior
results in a cumulative reward of 0. Separate temperature comfort ranges are defined for
summer and winter periods. The weights assigned to each term in the reward function allow
for adjusting the importance of each aspect during environment evaluation.</p>
<p>The core concept of the reward system in <em>Sinergym</em> is encapsulated by the following equation:</p>
<div class="math notranslate nohighlight">
\[r_t = - \omega \ \lambda_P \ P_t - (1 - \omega) \ \lambda_T \ (|T_t - T_{up}| + |T_t - T_{low}|)\]</div>
<p>Where: <br />
<span class="math notranslate nohighlight">\(P_t\)</span> represents power consumption, <br />
<span class="math notranslate nohighlight">\(T_t\)</span> is the current indoor temperature, <br />
<span class="math notranslate nohighlight">\(T_{up}\)</span> and <span class="math notranslate nohighlight">\(T_{low}\)</span> are the upper and lower comfort range limits, respectively, <br />
<span class="math notranslate nohighlight">\(\omega\)</span> is the weight assigned to power consumption, and consequently, <span class="math notranslate nohighlight">\(1 - \omega\)</span> represents the comfort weight, <br />
<span class="math notranslate nohighlight">\(\lambda_P\)</span> and <span class="math notranslate nohighlight">\(\lambda_T\)</span> are scaling constants for consumption and comfort penalties, respectively.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The constants <span class="math notranslate nohighlight">\(\lambda_P\)</span> and <span class="math notranslate nohighlight">\(\lambda_T\)</span> are configured to create a proportional
relationship between energy and comfort penalties, calibrating their magnitudes. When working
with different buildings, it‚Äôs crucial to adjust these constants to maintain a similar
magnitude of the reward components.</p>
</div>
<p>Different types of reward functions are designed based on specific details:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">LinearReward</span></code> implements a <strong>linear reward</strong> function, where discomfort is calculated as the absolute
difference between the current temperature and the comfort range.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ExpReward</span></code> is similar to the linear reward, but calculates discomfort using the <strong>exponential difference</strong>
between the current temperature and comfort ranges, resulting in a higher penalty for larger deviations
from target temperatures.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">HourlyLinearReward</span></code> adjusts the weight assigned to discomfort based on the <strong>hour of the day</strong>,
emphasizing energy consumption outside working hours more.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">NormalizedLinearReward</span></code> normalizes the reward components based on the maximum energy penalty
and comfort penalty, providing adaptability during the simulation. In this reward,
the <span class="math notranslate nohighlight">\(\lambda_P\)</span> and <span class="math notranslate nohighlight">\(\lambda_T\)</span> constants are not required to calibrate both magnitudes.</p></li>
</ul>
<blockquote>
<div><div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This reward function is not very precise at the beginning of the simulation, be careful with that.</p>
</div>
</div></blockquote>
<p>These reward functions have parameters in their constructors, the values of which may vary based on the building
used or other factors. By default, all environments use the <code class="docutils literal notranslate"><span class="pre">LinearReward</span></code> with default parameters for each
building. To change this, refer to the example in <a class="reference internal" href="notebooks/change_environment.html#Adding-a-new-reward"><span class="std std-ref">Adding a new reward</span></a>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When specifying a reward different from the default environment ID with <cite>gym.make</cite>, it‚Äôs crucial
to set the <cite>reward_kwargs</cite> that are required and thus don‚Äôt have a default value.</p>
</div>
<section id="reward-terms">
<h2><span class="section-number">8.1. </span>Reward terms<a class="headerlink" href="#reward-terms" title="Link to this heading">ÔÉÅ</a></h2>
<p>By default, reward functions return the <strong>reward scalar value</strong> and the <strong>terms</strong> used in their calculation.
The values of these terms depend on the specific reward function used and are automatically added to the
environment‚Äôs info dictionary. The structure typically matches the diagram below:</p>
<a class="reference internal image-reference" href="../_images/reward_terms.png"><img alt="Reward terms" class="align-center" src="../_images/reward_terms.png" style="width: 1197.0px; height: 572.5999999999999px;" />
</a>
</section>
<section id="custom-rewards">
<h2><span class="section-number">8.2. </span>Custom Rewards<a class="headerlink" href="#custom-rewards" title="Link to this heading">ÔÉÅ</a></h2>
<p>Defining custom reward functions is also straightforward. For instance, a reward signal that always returns
-1 can be implemented as shown:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sinergym.utils.rewards</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseReward</span>

<span class="k">class</span><span class="w"> </span><span class="nc">CustomReward</span><span class="p">(</span><span class="n">BaseReward</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Naive reward function.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CustomReward</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="p">{}</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;Eplus-discrete-stochastic-mixed-v1&#39;</span><span class="p">,</span> <span class="n">reward</span><span class="o">=</span><span class="n">CustomReward</span><span class="p">)</span>
</pre></div>
</div>
<p>For advanced reward functions, we recommend inheriting from our main class, <code class="docutils literal notranslate"><span class="pre">LinearReward</span></code>,
and overriding relevant methods. Our reward functions simplify observation processing to
extract consumption and comfort violation data, from which absolute penalty values are calculated.
Weighted reward terms are then calculated from these penalties and summed.</p>
<a class="reference internal image-reference" href="../_images/reward_structure.png"><img alt="Reward steps structure" class="align-center" src="../_images/reward_structure.png" style="width: 925.4px; height: 492.79999999999995px;" />
</a>
<p>By modularizing each of these steps, you can quickly and easily modify specific aspects of the
reward to create a new one, as demonstrated with our <em>exponential function reward version</em>, for example.</p>
<p><em>More reward functions will be included in the future, so stay tuned!</em></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="environments_registration.html" class="btn btn-neutral float-left" title="7. Environments Configuration and Registration" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="controllers.html" class="btn btn-neutral float-right" title="9. Controllers" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, J. Jim√©nez, J. G√≥mez, M. Molina, A. Manjavacas, A. Campoy.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        <span class="fa fa-book"> Other Versions</span>
        v: v3.3.0
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl>
            <dt>Tags</dt>
            <dd><a href="../../v1.4.0/pages/rewards.html">v1.4.0</a></dd>
            <dd><a href="../../v1.6.0/pages/rewards.html">v1.6.0</a></dd>
            <dd><a href="../../v1.7.0/pages/rewards.html">v1.7.0</a></dd>
            <dd><a href="../../v2.0.0/pages/rewards.html">v2.0.0</a></dd>
            <dd><a href="../../v2.1.0/pages/rewards.html">v2.1.0</a></dd>
            <dd><a href="../../v2.2.0/pages/rewards.html">v2.2.0</a></dd>
            <dd><a href="../../v2.3.0/pages/rewards.html">v2.3.0</a></dd>
            <dd><a href="../../v2.5.0/pages/rewards.html">v2.5.0</a></dd>
            <dd><a href="../../v3.1.0/pages/rewards.html">v3.1.0</a></dd>
            <dd><a href="../../v3.2.0/pages/rewards.html">v3.2.0</a></dd>
            <dd><a href="rewards.html">v3.3.0</a></dd>
            <dd><a href="../../v3.4.0/pages/rewards.html">v3.4.0</a></dd>
            <dd><a href="../../v3.5.0/pages/rewards.html">v3.5.0</a></dd>
            <dd><a href="../../v3.6.0/pages/rewards.html">v3.6.0</a></dd>
            <dd><a href="../../v3.7.0/pages/rewards.html">v3.7.0</a></dd>
            <dd><a href="../../v3.8.0/pages/rewards.html">v3.8.0</a></dd>
            <dd><a href="../../v3.9.0/pages/rewards.html">v3.9.0</a></dd>
        </dl>
        <dl>
            <dt>Branches</dt>
            <dd><a href="../../main/pages/rewards.html">main</a></dd>
        </dl>
    </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>