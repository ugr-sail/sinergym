{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Wrappers example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this notebook, we will explore *Sinergym*'s pre-defined wrappers and how to use them.\n",
    "\n",
    "You can also create your own wrappers by inheriting from *gym.Wrapper* or any of its variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "import sinergym\n",
    "from sinergym.utils.wrappers import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-objective wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MO-Gymnasium](https://github.com/Farama-Foundation/MO-Gymnasium) is an open-source Python library for developing and comparing multi-objective reinforcement learning algorithms. \n",
    "\n",
    "Available MO-Gymnasium environments return a reward vector instead of a scalar value, one for each objective.\n",
    "\n",
    "This wrapper enables *Sinergym* to return a reward vector. This way, *Sinergym* is made compatible with both multi-objective algorithms and algorithms that work with a traditional reward value.\n",
    "\n",
    "We can transform the returned reward into a vector using as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Name: Eplus-5zone-hot-discrete-v1\u001b[0m\n",
      "#==============================================================================================#\n",
      "\u001b[38;20m[MODEL] (INFO) : Working directory created: /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Model Config is correct.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Building model Output:Variable updated with defined variable names.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Updated building model Output:Meter with meter names.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Runperiod established.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : timesteps per episode: 35040\u001b[0m\n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment created successfully.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : New Discrete Space and mapping: Discrete(10)\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Make sure that the action space is compatible and contained in the original environment.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Wrapper initialized\u001b[0m\n",
      "\u001b[38;20m[WRAPPER MultiObjectiveReward] (INFO) : wrapper initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Eplus-5zone-hot-discrete-v1')\n",
    "env = MultiObjectiveReward(env, reward_terms=['energy_term', 'comfort_term'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that `reward_terms` are available in the `info` dict returned by the environment's `step` method. Otherwise, an execution error will occur.\n",
    "\n",
    "By default, *Sinergym* environments return all reward terms of the reward class in the `info` dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1: Eplus-5zone-hot-discrete-v1\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode directory created.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Adapting weather to building model.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path in /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1/episode-1/output.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [Eplus-5zone-hot-discrete-v1]\u001b[0m                  \n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:00<00:00, 4527.09%/s, 100% completed][-0.005897377870609513, -0.09451834601888898]\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "action = env.action_space.sample()\n",
    "obs, reward, terminated, truncated, info = env.step(action)\n",
    "env.close()\n",
    "\n",
    "print(reward)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous observation wrappers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wrapper will add previous timestep observation values to the current environment observation. \n",
    "\n",
    "You can select the variables whose previous observed values should be tracked. The observation space will be updated with the corresponding new dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#   \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment.\u001b[0m                               \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Name: Eplus-5zone-hot-discrete-v1\u001b[0m                             \n",
      "#==============================================================================================# \n",
      "\u001b[38;20m[MODEL] (INFO) : Working directory created: /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Model Config is correct.\u001b[0m                                            \n",
      "\u001b[38;20m[MODEL] (INFO) : Building model Output:Variable updated with defined variable names.\u001b[0m \n",
      "\u001b[38;20m[MODEL] (INFO) : Updated building model Output:Meter with meter names.\u001b[0m               \n",
      "\u001b[38;20m[MODEL] (INFO) : Runperiod established.\u001b[0m                                              \n",
      "\u001b[38;20m[MODEL] (INFO) : Episode length (seconds): 31536000.0\u001b[0m                                \n",
      "\u001b[38;20m[MODEL] (INFO) : timestep size (seconds): 900.0\u001b[0m                                      \n",
      "\u001b[38;20m[MODEL] (INFO) : timesteps per episode: 35040\u001b[0m                                        \n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m                                       \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment created successfully.\u001b[0m                             \n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : New Discrete Space and mapping: Discrete(10)\u001b[0m        \n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Make sure that the action space is compatible and contained in the original environment.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Wrapper initialized\u001b[0m                                 \n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:12<00:00,  8.06%/s, 100% completed]\n",
      "\u001b[38;20m[WRAPPER PreviousObservationWrapper] (INFO) : Wrapper initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Eplus-5zone-hot-discrete-v1')\n",
    "env = PreviousObservationWrapper(env, previous_variables=[\n",
    "    'htg_setpoint',\n",
    "    'clg_setpoint',\n",
    "    'air_temperature'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how the observation values have been updated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1: Eplus-5zone-hot-discrete-v1\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode directory created.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Adapting weather to building model.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path in /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1/episode-1/output.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [Eplus-5zone-hot-discrete-v1]\u001b[0m                  \n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:00<00:00, 9127.97%/s, 100% completed]NEW OBSERVATION:  {'month': np.float32(1.0), 'day_of_month': np.float32(1.0), 'hour': np.float32(0.0), 'outdoor_temperature': np.float32(4.8), 'outdoor_humidity': np.float32(61.0), 'wind_speed': np.float32(4.65), 'wind_direction': np.float32(160.0), 'diffuse_solar_radiation': np.float32(0.0), 'direct_solar_radiation': np.float32(0.0), 'htg_setpoint': np.float32(19.0), 'clg_setpoint': np.float32(23.25), 'air_temperature': np.float32(19.77215), 'air_humidity': np.float32(28.321066), 'people_occupant': np.float32(0.0), 'co2_emission': np.float32(0.0), 'HVAC_electricity_demand_rate': np.float32(3497.2122), 'total_electricity_HVAC': np.float32(3668829.2), 'htg_setpoint_previous': np.float32(12.8), 'clg_setpoint_previous': np.float32(40.0), 'air_temperature_previous': np.float32(19.952078)}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "obs, _, _, _, _ = env.step(env.action_space.sample())\n",
    "obs_dict = env.get_obs_dict(obs)\n",
    "env.close()\n",
    "\n",
    "print('NEW OBSERVATION: ', obs_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datetime wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wrapper will replace the `day` value with the `is_weekend` flag, and `hour` and `month` with codified *sin* and *cos* values.\n",
    "\n",
    "The observation space is also automatically updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#   \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment.\u001b[0m                               \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Name: Eplus-5zone-hot-discrete-v1\u001b[0m                             \n",
      "#==============================================================================================# \n",
      "\u001b[38;20m[MODEL] (INFO) : Working directory created: /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res2\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Model Config is correct.\u001b[0m                                            \n",
      "\u001b[38;20m[MODEL] (INFO) : Building model Output:Variable updated with defined variable names.\u001b[0m \n",
      "\u001b[38;20m[MODEL] (INFO) : Updated building model Output:Meter with meter names.\u001b[0m               \n",
      "\u001b[38;20m[MODEL] (INFO) : Runperiod established.\u001b[0m                                              \n",
      "\u001b[38;20m[MODEL] (INFO) : Episode length (seconds): 31536000.0\u001b[0m                                \n",
      "\u001b[38;20m[MODEL] (INFO) : timestep size (seconds): 900.0\u001b[0m                                      \n",
      "\u001b[38;20m[MODEL] (INFO) : timesteps per episode: 35040\u001b[0m                                        \n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m                                       \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment created successfully.\u001b[0m                             \n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : New Discrete Space and mapping: Discrete(10)\u001b[0m        \n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Make sure that the action space is compatible and contained in the original environment.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Wrapper initialized\u001b[0m                                 \n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:15<00:00,  6.49%/s, 100% completed]\n",
      "\u001b[38;20m[WRAPPER DatetimeWrapper] (INFO) : Wrapper initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Eplus-5zone-hot-discrete-v1')\n",
    "env = DatetimeWrapper(env)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wrapper removes the observation variables `month`, `day`, and `hour`, and replace them by `month_sin`, `month_cos`, `is_weekend`, `hour_sin`, and `hour_cos`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1: Eplus-5zone-hot-discrete-v1\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode directory created.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Adapting weather to building model.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path in /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res2/episode-1/output.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [Eplus-5zone-hot-discrete-v1]\u001b[0m                  \n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:00<00:00, 6941.45%/s, 100% completed]NEW OBSERVATION:  {'month_cos': np.float32(1.0), 'month_sin': np.float32(0.0), 'is_weekend': np.float32(0.0), 'hour_cos': np.float32(1.0), 'hour_sin': np.float32(0.0), 'outdoor_temperature': np.float32(4.8), 'outdoor_humidity': np.float32(61.0), 'wind_speed': np.float32(4.65), 'wind_direction': np.float32(160.0), 'diffuse_solar_radiation': np.float32(0.0), 'direct_solar_radiation': np.float32(0.0), 'htg_setpoint': np.float32(19.0), 'clg_setpoint': np.float32(23.25), 'air_temperature': np.float32(19.77215), 'air_humidity': np.float32(28.321066), 'people_occupant': np.float32(0.0), 'co2_emission': np.float32(0.0), 'HVAC_electricity_demand_rate': np.float32(3497.2122), 'total_electricity_HVAC': np.float32(3668829.2)}\n",
      "NEW OBSERVATION:  {'month_cos': np.float32(1.0), 'month_sin': np.float32(0.0), 'is_weekend': np.float32(0.0), 'hour_cos': np.float32(1.0), 'hour_sin': np.float32(0.0), 'outdoor_temperature': np.float32(4.8), 'outdoor_humidity': np.float32(61.0), 'wind_speed': np.float32(4.65), 'wind_direction': np.float32(160.0), 'diffuse_solar_radiation': np.float32(0.0), 'direct_solar_radiation': np.float32(0.0), 'htg_setpoint': np.float32(19.0), 'clg_setpoint': np.float32(23.25), 'air_temperature': np.float32(19.77215), 'air_humidity': np.float32(28.321066), 'people_occupant': np.float32(0.0), 'co2_emission': np.float32(0.0), 'HVAC_electricity_demand_rate': np.float32(3497.2122), 'total_electricity_HVAC': np.float32(3668829.2)}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "obs, _, _, _, _ = env.step(env.action_space.sample())\n",
    "obs_dict = env.get_obs_dict(obs)\n",
    "env.close()\n",
    "print('NEW OBSERVATION: ', obs_dict)\n",
    "\n",
    "print('NEW OBSERVATION: ', obs_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action normalization wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of how to normalize a continuous action space using the `NormalizeAction` wrapper.\n",
    "\n",
    "If the normalization range is not defined, it will be `[-1,1]` by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#   \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment.\u001b[0m                               \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Name: Eplus-5zone-hot-continuous-v1\u001b[0m                           \n",
      "#==============================================================================================# \n",
      "\u001b[38;20m[MODEL] (INFO) : Working directory created: /workspaces/sinergym/examples/Eplus-5zone-hot-continuous-v1-res1\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Model Config is correct.\u001b[0m                                            \n",
      "\u001b[38;20m[MODEL] (INFO) : Building model Output:Variable updated with defined variable names.\u001b[0m \n",
      "\u001b[38;20m[MODEL] (INFO) : Updated building model Output:Meter with meter names.\u001b[0m               \n",
      "\u001b[38;20m[MODEL] (INFO) : Runperiod established.\u001b[0m                                              \n",
      "\u001b[38;20m[MODEL] (INFO) : Episode length (seconds): 31536000.0\u001b[0m                                \n",
      "\u001b[38;20m[MODEL] (INFO) : timestep size (seconds): 900.0\u001b[0m                                      \n",
      "\u001b[38;20m[MODEL] (INFO) : timesteps per episode: 35040\u001b[0m                                        \n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m                                       \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment created successfully.\u001b[0m                             \n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:08<00:00, 11.40%/s, 100% completed]\n",
      "ORIGINAL ACTION SPACE:  Box([12.   23.25], [23.25 30.  ], (2,), float32)\n",
      "\u001b[38;20m[WRAPPER NormalizeAction] (INFO) : New normalized action space: Box(-1.0, 1.0, (2,), float32)\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeAction] (INFO) : Wrapper initialized.\u001b[0m\n",
      "WRAPPED ACTION SPACE:  Box(-1.0, 1.0, (2,), float32)\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1: Eplus-5zone-hot-continuous-v1\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode directory created.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Adapting weather to building model.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path in /workspaces/sinergym/examples/Eplus-5zone-hot-continuous-v1-res1/episode-1/output.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
      "Normalized action:  [-0.52202827 -0.46923232]\n",
      "Action performed in the simulator:  [14.688591003417969, 25.04134178161621]\n",
      "Normalized action:  [-0.5633869   0.09416266]\n",
      "Action performed in the simulator:  [14.455948829650879, 26.942798614501953]\n",
      "Normalized action:  [ 0.04455094 -0.9088971 ]\n",
      "Action performed in the simulator:  [17.875598907470703, 23.557472229003906]\n",
      "Normalized action:  [0.05806986 0.1181407 ]\n",
      "Action performed in the simulator:  [17.951642990112305, 27.023725509643555]\n",
      "Normalized action:  [ 0.7687502  -0.16491799]\n",
      "Action performed in the simulator:  [21.94921875, 26.068401336669922]\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [Eplus-5zone-hot-continuous-v1]\u001b[0m               \n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:00<00:00, 3270.13%/s, 100% completed]"
     ]
    }
   ],
   "source": [
    "# Create a continuous environment\n",
    "env = gym.make('Eplus-5zone-hot-continuous-v1')\n",
    "print('ORIGINAL ACTION SPACE: ', env.get_wrapper_attr('action_space'))\n",
    "\n",
    "# Apply the normalization wrapper\n",
    "env = NormalizeAction(env, normalize_range=(-1.0, 1.0))\n",
    "print('WRAPPED ACTION SPACE: ', env.get_wrapper_attr('action_space'))\n",
    "\n",
    "env.reset()\n",
    "for i in range(5):\n",
    "    action = env.action_space.sample()\n",
    "    print('Normalized action: ', action)\n",
    "    _, _, _, _, info = env.step(action)\n",
    "    print('Action performed in the simulator: ', info['action'])\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action discretization wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how to discretize a continuous action space. We will need to specify the **new discrete action space** and an **action mapping function** whose output matches the original unwrapped action space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Name: Eplus-5zone-hot-continuous-v1\u001b[0m\n",
      "#==============================================================================================#\n",
      "\u001b[38;20m[MODEL] (INFO) : Working directory created: /workspaces/sinergym/examples/Eplus-5zone-hot-continuous-v1-res1\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Model Config is correct.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Building model Output:Variable updated with defined variable names.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Updated building model Output:Meter with meter names.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Runperiod established.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : timesteps per episode: 35040\u001b[0m\n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment created successfully.\u001b[0m\n",
      "ORIGINAL ACTION SPACE:  Box([12.   23.25], [23.25 30.  ], (2,), float32)\n",
      "IS DISCRETE?:  False\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : New Discrete Space and mapping: Discrete(10)\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Make sure that the action space is compatible and contained in the original environment.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Wrapper initialized\u001b[0m\n",
      "WRAPPED ACTION SPACE:  Discrete(10)\n",
      "IS DISCRETE?:  True\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1: Eplus-5zone-hot-continuous-v1\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode directory created.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Adapting weather to building model.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path in /workspaces/sinergym/examples/Eplus-5zone-hot-continuous-v1-res1/episode-1/output.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
      "ACTION DISCRETE:  3\n",
      "Action done in simulator:  [15.0, 27.0]\n",
      "ACTION DISCRETE:  0\n",
      "Action done in simulator:  [12.0, 30.0]\n",
      "ACTION DISCRETE:  5\n",
      "Action done in simulator:  [17.0, 25.0]\n",
      "ACTION DISCRETE:  5\n",
      "Action done in simulator:  [17.0, 25.0]\n",
      "ACTION DISCRETE:  6\n",
      "Action done in simulator:  [18.0, 24.0]\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [Eplus-5zone-hot-continuous-v1]\u001b[0m                \n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:00<00:00, 9598.61%/s, 100% completed]"
     ]
    }
   ],
   "source": [
    "# We will create a continuous environment\n",
    "env = gym.make('Eplus-5zone-hot-continuous-v1')\n",
    "print('ORIGINAL ACTION SPACE: ', env.get_wrapper_attr('action_space'))\n",
    "print('IS DISCRETE?: ', env.get_wrapper_attr('is_discrete'))\n",
    "\n",
    "# Defining new discrete space and action mapping function\n",
    "new_discrete_space = gym.spaces.Discrete(10)  # Action values [0,9]\n",
    "\n",
    "\n",
    "def action_mapping_function(action):\n",
    "    mapping = {\n",
    "        0: np.array([12, 30], dtype=np.float32),\n",
    "        1: np.array([13, 29], dtype=np.float32),\n",
    "        2: np.array([14, 28], dtype=np.float32),\n",
    "        3: np.array([15, 27], dtype=np.float32),\n",
    "        4: np.array([16, 26], dtype=np.float32),\n",
    "        5: np.array([17, 25], dtype=np.float32),\n",
    "        6: np.array([18, 24], dtype=np.float32),\n",
    "        7: np.array([19, 23.25], dtype=np.float32),\n",
    "        8: np.array([20, 23.25], dtype=np.float32),\n",
    "        9: np.array([21, 23.25], dtype=np.float32)\n",
    "    }\n",
    "\n",
    "    return mapping[action]\n",
    "\n",
    "\n",
    "# Apply the discretization wrapper\n",
    "env = DiscretizeEnv(env, discrete_space=new_discrete_space,\n",
    "                    action_mapping=action_mapping_function)\n",
    "print('WRAPPED ACTION SPACE: ', env.get_wrapper_attr('action_space'))\n",
    "print('IS DISCRETE?: ', env.get_wrapper_attr('is_discrete'))\n",
    "env.reset()\n",
    "for i in range(5):\n",
    "    action = env.action_space.sample()\n",
    "    print('ACTION DISCRETE: ', action)\n",
    "    _, _, _, _, info = env.step(action)\n",
    "    print('Action done in simulator: ', info['action'])\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete incremental wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wrapper updates an environment to utilize an incremental setpoint action space.It converts the environment into a *discrete* environment with an action mapping function and action space depending on the `step` and `delta` values specified. \n",
    "\n",
    "The action is added to the **current setpoint** value instead of overwriting the latest action. Thus, the action is the current setpoint values with the applied increment/decrement, rather than the discrete value action that defines the increment/decrement itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#   \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment.\u001b[0m                               \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Name: Eplus-5zone-hot-continuous-v1\u001b[0m                           \n",
      "#==============================================================================================# \n",
      "\u001b[38;20m[MODEL] (INFO) : Working directory created: /workspaces/sinergym/examples/Eplus-5zone-hot-continuous-v1-res1\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Model Config is correct.\u001b[0m                                            \n",
      "\u001b[38;20m[MODEL] (INFO) : Building model Output:Variable updated with defined variable names.\u001b[0m \n",
      "\u001b[38;20m[MODEL] (INFO) : Updated building model Output:Meter with meter names.\u001b[0m               \n",
      "\u001b[38;20m[MODEL] (INFO) : Runperiod established.\u001b[0m                                              \n",
      "\u001b[38;20m[MODEL] (INFO) : Episode length (seconds): 31536000.0\u001b[0m                                \n",
      "\u001b[38;20m[MODEL] (INFO) : timestep size (seconds): 900.0\u001b[0m                                      \n",
      "\u001b[38;20m[MODEL] (INFO) : timesteps per episode: 35040\u001b[0m                                        \n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m                                       \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment created successfully.\u001b[0m                             \n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:09<00:00, 10.55%/s, 100% completed]\n",
      "ORIGINAL ACTION SPACE:  Box([12.   23.25], [23.25 30.  ], (2,), float32)\n",
      "\u001b[38;20m[WRAPPER DiscreteIncrementalWrapper] (INFO) : New incremental action mapping: 17\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscreteIncrementalWrapper] (INFO) : {0: array([0., 0.], dtype=float32), 1: array([0.5, 0. ], dtype=float32), 2: array([1., 0.], dtype=float32), 3: array([1.5, 0. ], dtype=float32), 4: array([2., 0.], dtype=float32), 5: array([-0.5,  0. ], dtype=float32), 6: array([-1.,  0.], dtype=float32), 7: array([-1.5,  0. ], dtype=float32), 8: array([-2.,  0.], dtype=float32), 9: array([0. , 0.5], dtype=float32), 10: array([0., 1.], dtype=float32), 11: array([0. , 1.5], dtype=float32), 12: array([0., 2.], dtype=float32), 13: array([ 0. , -0.5], dtype=float32), 14: array([ 0., -1.], dtype=float32), 15: array([ 0. , -1.5], dtype=float32), 16: array([ 0., -2.], dtype=float32)}\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscreteIncrementalWrapper] (INFO) : Wrapper initialized\u001b[0m\n",
      "WRAPPED ACTION SPACE:  Discrete(17)\n",
      "WRAPPED ACTION MAPPING:  <bound method DiscreteIncrementalWrapper.action_mapping of <DiscreteIncrementalWrapper<OrderEnforcing<PassiveEnvChecker<EplusEnv<Eplus-5zone-hot-continuous-v1>>>>>>\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Eplus-5zone-hot-continuous-v1')\n",
    "print('ORIGINAL ACTION SPACE: ', env.get_wrapper_attr('action_space'))\n",
    "\n",
    "env = DiscreteIncrementalWrapper(\n",
    "    env, initial_values=[21.0, 25.0], delta_temp=2, step_temp=0.5)\n",
    "\n",
    "print('WRAPPED ACTION SPACE: ', env.get_wrapper_attr('action_space'))\n",
    "print('WRAPPED ACTION MAPPING: ', env.get_wrapper_attr('action_mapping'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum and minimum values defined when creating the action mapping are read from the environment action space, ensuring that the setpoint increments and decrements do not exceed the corresponding limits.\n",
    "\n",
    "The `delta` and `step` values are used to determine how the discrete space of these increments and decrements will be constructed.\n",
    "\n",
    "Here's an example of how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1: Eplus-5zone-hot-continuous-v1\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode directory created.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Adapting weather to building model.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path in /workspaces/sinergym/examples/Eplus-5zone-hot-continuous-v1-res1/episode-1/output.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
      "CURRENT SETPOINTS VALUES:  [21. 25.]\n",
      "Action number  0 :  [0. 2.]\n",
      "Setpoints update:  [21.0, 27.0]\n",
      "Action number  1 :  [0. 1.]\n",
      "Setpoints update:  [21.0, 28.0]\n",
      "Action number  2 :  [0.  1.5]\n",
      "Setpoints update:  [21.0, 29.5]\n",
      "Action number  3 :  [-2.  0.]\n",
      "Setpoints update:  [19.0, 29.5]\n",
      "Action number  4 :  [0.  1.5]\n",
      "Setpoints update:  [19.0, 30.0]\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [Eplus-5zone-hot-continuous-v1]\u001b[0m                \n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:00<00:00, 8961.81%/s, 100% completed]"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "print('CURRENT SETPOINTS VALUES: ', env.get_wrapper_attr('current_setpoints'))\n",
    "\n",
    "for i in range(5):\n",
    "    action = env.action_space.sample()\n",
    "    _, _, _, _, info = env.step(action)\n",
    "    print('Action number ', i, ': ',\n",
    "          env.get_wrapper_attr('action_mapping')(action))\n",
    "    print('Setpoints update: ', info['action'])\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wrapper is used to transform observations received from the simulator to values between in range `[-1, 1]`.\n",
    "\n",
    "It is based on [Gymnasium's dynamic normalization wrapper](https://gymnasium.farama.org/_modules/gymnasium/wrappers/normalize/#NormalizeObservation). \n",
    "\n",
    "Until properly calibrated, it may not be precise, and the values may often be out of range, so use this wrapper with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#   \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment.\u001b[0m                               \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Name: Eplus-5zone-hot-discrete-v1\u001b[0m                             \n",
      "#==============================================================================================# \n",
      "\u001b[38;20m[MODEL] (INFO) : Working directory created: /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Model Config is correct.\u001b[0m                                            \n",
      "\u001b[38;20m[MODEL] (INFO) : Building model Output:Variable updated with defined variable names.\u001b[0m \n",
      "\u001b[38;20m[MODEL] (INFO) : Updated building model Output:Meter with meter names.\u001b[0m               \n",
      "\u001b[38;20m[MODEL] (INFO) : Runperiod established.\u001b[0m                                              \n",
      "\u001b[38;20m[MODEL] (INFO) : Episode length (seconds): 31536000.0\u001b[0m                                \n",
      "\u001b[38;20m[MODEL] (INFO) : timestep size (seconds): 900.0\u001b[0m                                      \n",
      "\u001b[38;20m[MODEL] (INFO) : timesteps per episode: 35040\u001b[0m                                        \n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m                                       \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment created successfully.\u001b[0m                             \n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : New Discrete Space and mapping: Discrete(10)\u001b[0m        \n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Make sure that the action space is compatible and contained in the original environment.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Wrapper initialized\u001b[0m                                 \n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:07<00:00, 12.90%/s, 100% completed]\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Wrapper initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Original env\n",
    "env = gym.make('Eplus-5zone-hot-discrete-v1')\n",
    "\n",
    "# Normalized env\n",
    "env = NormalizeObservation(\n",
    "    env=env)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check how the specified variables have been correctly normalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1: Eplus-5zone-hot-discrete-v1\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode directory created.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Adapting weather to building model.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path in /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1/episode-1/output.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Normalization calibration saved.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [Eplus-5zone-hot-discrete-v1]\u001b[0m                  \n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:00<00:00, 6032.45%/s, 100% completed]OBSERVATION WITH NORMALIZATION:  {'month': np.float32(0.005000767), 'day_of_month': np.float32(0.005000767), 'hour': np.float32(0.0), 'outdoor_temperature': np.float32(0.98759085), 'outdoor_humidity': np.float32(-0.9745623), 'wind_speed': np.float32(0.99739647), 'wind_direction': np.float32(0.9908533), 'diffuse_solar_radiation': np.float32(0.0), 'direct_solar_radiation': np.float32(0.0), 'htg_setpoint': np.float32(0.9994412), 'clg_setpoint': np.float32(-0.9994248), 'air_temperature': np.float32(-0.44181496), 'air_humidity': np.float32(0.14094329), 'people_occupant': np.float32(0.0), 'co2_emission': np.float32(0.0), 'HVAC_electricity_demand_rate': np.float32(1.0000393), 'total_electricity_HVAC': np.float32(1.0000393)}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "obs, _, _, _, _ = env.step(env.action_space.sample())\n",
    "obs_dict = env.get_obs_dict(obs)\n",
    "env.close()\n",
    "\n",
    "print('OBSERVATION WITH NORMALIZATION: ', obs_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging and storing data with logger wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoggerWrapper layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wrapper uses *Sinergym*'s `LoggerStorage` class to properly capture the interaction flow with the environment.\n",
    "\n",
    "The class used by the wrapper can be replaced with a different back-end. It can then be combined with different wrappers to save the stored data, such as `CSVLogger` or `WandBLogger`. For more information about *Sinergym*'s logger, visit [Logging System Overview](https://ugr-sail.github.io/sinergym/compilation/main/pages/logging.html#logging-system-overview), [Logger Wrappers](https://ugr-sail.github.io/sinergym/compilation/main/pages/wrappers.html#logger-wrappers) and [an example about custom loggers](https://ugr-sail.github.io/sinergym/compilation/main/pages/notebooks/personalize_loggerwrapper.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#   \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment.\u001b[0m                               \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Name: Eplus-5zone-hot-discrete-v1\u001b[0m                             \n",
      "#==============================================================================================# \n",
      "\u001b[38;20m[MODEL] (INFO) : Working directory created: /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Model Config is correct.\u001b[0m                                            \n",
      "\u001b[38;20m[MODEL] (INFO) : Building model Output:Variable updated with defined variable names.\u001b[0m \n",
      "\u001b[38;20m[MODEL] (INFO) : Updated building model Output:Meter with meter names.\u001b[0m               \n",
      "\u001b[38;20m[MODEL] (INFO) : Runperiod established.\u001b[0m                                              \n",
      "\u001b[38;20m[MODEL] (INFO) : Episode length (seconds): 31536000.0\u001b[0m                                \n",
      "\u001b[38;20m[MODEL] (INFO) : timestep size (seconds): 900.0\u001b[0m                                      \n",
      "\u001b[38;20m[MODEL] (INFO) : timesteps per episode: 35040\u001b[0m                                        \n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m                                       \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment created successfully.\u001b[0m                             \n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : New Discrete Space and mapping: Discrete(10)\u001b[0m        \n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Make sure that the action space is compatible and contained in the original environment.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Wrapper initialized\u001b[0m                                 \n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:09<00:00, 10.01%/s, 100% completed]\n",
      "\u001b[38;20m[WRAPPER LoggerWrapper] (INFO) : Wrapper initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Eplus-5zone-hot-discrete-v1')\n",
    "env = LoggerWrapper(env, storage_class=LoggerStorage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wrapper enables the use of a `LoggerStorage` instance within the environment class and automatically captures interaction data while actions are sent by an agent. At each reset, the data from this class is cleared to start the next episode. The idea is to combine it with other output loggers like those listed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoggerCSV layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m[WRAPPER CSVLogger] (INFO) : Wrapper initialized.\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1: Eplus-5zone-hot-discrete-v1\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode directory created.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Adapting weather to building model.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path in /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1/episode-1/output.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER CSVLogger] (INFO) : Environment closed, data updated in monitor and progress.csv.\u001b[0m\n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:23<00:00,  4.34%/s, 100% completed]\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [Eplus-5zone-hot-discrete-v1]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = CSVLogger(env)\n",
    "\n",
    "env.reset()\n",
    "truncated = terminated = False\n",
    "current_month = 0\n",
    "\n",
    "while not (terminated or truncated):\n",
    "    a = env.action_space.sample()\n",
    "    _, _, terminated, truncated, _ = env.step(a)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `LoggerWrapper` is applied, this wrapper can be used to output episode data through *Sinergym*’s output, along with summary metrics added to CSV files. More details on this structure can be found in [OutputFormat](https://ugr-sail.github.io/sinergym/compilation/main/pages/output.html). \n",
    "\n",
    "*Sinergym* will raise an error if this wrapper is used without first enabling `LoggerWrapper` or a similar custom logger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WandBLogger layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = WandBLogger(env = Env,\n",
    "#                 entity = <wandb_account_entity>,\n",
    "#                 project_name = <wandb_project_name>,\n",
    "#                 run_name = <run_name>\n",
    "#                 group = 'Notebook_example',\n",
    "#                 tags: ['tag1','tag2'],\n",
    "#                 save_code = False,\n",
    "#                 dump_frequency = 1000,\n",
    "#                 artifact_save = True,\n",
    "#                 artifact_type = 'output',\n",
    "#                 excluded_info_keys = ['reward',\n",
    "#                                   'action',\n",
    "#                                   'timestep',\n",
    "#                                   'month',\n",
    "#                                   'day',\n",
    "#                                   'hour',\n",
    "#                                   'time_elapsed(hours)',\n",
    "#                                   'reward_weight',\n",
    "#                                   'is_raining'],\n",
    "#                 excluded_episode_summary_keys = ['terminated',\n",
    "#                                              'truncated']):\n",
    "\n",
    "# env.reset()\n",
    "# truncated = terminated = False\n",
    "# current_month = 0\n",
    "# while not (terminated or truncated):\n",
    "#     a = env.action_space.sample()\n",
    "#     _,_,terminated,truncated,_=env.step(a)\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to `CSVLogger`, this wrapper requires the environment to have been previously encapsulated by a `LoggerWrapper` or any custom logger.\n",
    "\n",
    "The user must have a pre-existing **Weights and Biases** account and correctly configured it. \n",
    "\n",
    "This wrapper does not override `CSVLogger`, so both can be applied simultaneously."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-observation wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wrapper stacks observations in a history queue, whose size can be customized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Name: Eplus-5zone-hot-discrete-v1\u001b[0m\n",
      "#==============================================================================================#\n",
      "\u001b[38;20m[MODEL] (INFO) : Working directory created: /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Model Config is correct.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Building model Output:Variable updated with defined variable names.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Updated building model Output:Meter with meter names.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Runperiod established.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : timesteps per episode: 35040\u001b[0m\n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment created successfully.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : New Discrete Space and mapping: Discrete(10)\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Make sure that the action space is compatible and contained in the original environment.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Wrapper initialized\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1: Eplus-5zone-hot-discrete-v1\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode directory created.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Adapting weather to building model.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path in /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1/episode-1/output.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
      "BEFORE MULTI OBSERVATION:  [1.00000000e+00 1.00000000e+00 0.00000000e+00 4.40000010e+00\n",
      " 6.50000000e+01 3.87500000e+00 1.45000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.28000002e+01 4.00000000e+01 1.99520779e+01\n",
      " 2.82156696e+01 0.00000000e+00 0.00000000e+00 1.17947556e+02\n",
      " 1.06152805e+05]\n",
      "\u001b[38;20m[WRAPPER MultiObsWrapper] (INFO) : Wrapper initialized.\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#      \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m                                         \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 2: Eplus-5zone-hot-discrete-v1\u001b[0m                          \n",
      "#----------------------------------------------------------------------------------------------#   \n",
      "\u001b[38;20m[MODEL] (INFO) : Episode directory created.\u001b[0m                                            \n",
      "\u001b[38;20m[MODEL] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m           \n",
      "\u001b[38;20m[MODEL] (INFO) : Adapting weather to building model.\u001b[0m                                   \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path in /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1/episode-2/output.\u001b[0m\n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:00<00:00, 476.79%/s, 100% completed]\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 2 started.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation Progress [Episode 2]: 100%|██████████| 100/100 [00:00<00:00, 194180.74%/s, 100% completed] "
     ]
    }
   ],
   "source": [
    "# Original environment\n",
    "env = gym.make('Eplus-5zone-hot-discrete-v1')\n",
    "obs, info = env.reset()\n",
    "print('BEFORE MULTI OBSERVATION: ', obs)\n",
    "\n",
    "# Multi-observation environment with a queue of size 5\n",
    "env = MultiObsWrapper(env, n=5, flatten=True)\n",
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MULTI OBSERVATION: \n",
      " [1.00000000e+00 1.00000000e+00 0.00000000e+00 4.40000010e+00\n",
      " 6.50000000e+01 3.87500000e+00 1.45000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.28000002e+01 4.00000000e+01 1.99520779e+01\n",
      " 2.82156696e+01 0.00000000e+00 0.00000000e+00 1.17947556e+02\n",
      " 1.06152805e+05 1.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      " 4.40000010e+00 6.50000000e+01 3.87500000e+00 1.45000000e+02\n",
      " 0.00000000e+00 0.00000000e+00 1.28000002e+01 4.00000000e+01\n",
      " 1.99520779e+01 2.82156696e+01 0.00000000e+00 0.00000000e+00\n",
      " 1.17947556e+02 1.06152805e+05 1.00000000e+00 1.00000000e+00\n",
      " 0.00000000e+00 4.40000010e+00 6.50000000e+01 3.87500000e+00\n",
      " 1.45000000e+02 0.00000000e+00 0.00000000e+00 1.28000002e+01\n",
      " 4.00000000e+01 1.99520779e+01 2.82156696e+01 0.00000000e+00\n",
      " 0.00000000e+00 1.17947556e+02 1.06152805e+05 1.00000000e+00\n",
      " 1.00000000e+00 0.00000000e+00 4.40000010e+00 6.50000000e+01\n",
      " 3.87500000e+00 1.45000000e+02 0.00000000e+00 0.00000000e+00\n",
      " 1.28000002e+01 4.00000000e+01 1.99520779e+01 2.82156696e+01\n",
      " 0.00000000e+00 0.00000000e+00 1.17947556e+02 1.06152805e+05\n",
      " 1.00000000e+00 1.00000000e+00 0.00000000e+00 4.40000010e+00\n",
      " 6.50000000e+01 3.87500000e+00 1.45000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.28000002e+01 4.00000000e+01 1.99520779e+01\n",
      " 2.82156696e+01 0.00000000e+00 0.00000000e+00 1.17947556e+02\n",
      " 1.06152805e+05]\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [Eplus-5zone-hot-discrete-v1]\u001b[0m                 \n",
      "Simulation Progress [Episode 2]: 100%|██████████| 100/100 [00:00<00:00, 6459.04%/s, 100% completed]"
     ]
    }
   ],
   "source": [
    "print('MULTI OBSERVATION: \\n', obs)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather forecasting wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wrapper adds weather forecast information to the current observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#   \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment.\u001b[0m                               \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Name: Eplus-5zone-hot-discrete-v1\u001b[0m                             \n",
      "#==============================================================================================# \n",
      "\u001b[38;20m[MODEL] (INFO) : Working directory created: /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Model Config is correct.\u001b[0m                                            \n",
      "\u001b[38;20m[MODEL] (INFO) : Building model Output:Variable updated with defined variable names.\u001b[0m \n",
      "\u001b[38;20m[MODEL] (INFO) : Updated building model Output:Meter with meter names.\u001b[0m               \n",
      "\u001b[38;20m[MODEL] (INFO) : Runperiod established.\u001b[0m                                              \n",
      "\u001b[38;20m[MODEL] (INFO) : Episode length (seconds): 31536000.0\u001b[0m                                \n",
      "\u001b[38;20m[MODEL] (INFO) : timestep size (seconds): 900.0\u001b[0m                                      \n",
      "\u001b[38;20m[MODEL] (INFO) : timesteps per episode: 35040\u001b[0m                                        \n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m                                       \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment created successfully.\u001b[0m                             \n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : New Discrete Space and mapping: Discrete(10)\u001b[0m        \n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Make sure that the action space is compatible and contained in the original environment.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Wrapper initialized\u001b[0m                                 \n",
      "Simulation Progress [Episode 2]: 100%|██████████| 100/100 [00:09<00:00, 10.14%/s, 100% completed]\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1: Eplus-5zone-hot-discrete-v1\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode directory created.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Adapting weather to building model.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path in /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1/episode-1/output.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
      "OBSERVATION VARIABLES BEFORE WEATHER FORECASTING:  ['month', 'day_of_month', 'hour', 'outdoor_temperature', 'outdoor_humidity', 'wind_speed', 'wind_direction', 'diffuse_solar_radiation', 'direct_solar_radiation', 'htg_setpoint', 'clg_setpoint', 'air_temperature', 'air_humidity', 'people_occupant', 'co2_emission', 'HVAC_electricity_demand_rate', 'total_electricity_HVAC']\n",
      "OBSERVATION BEFORE WEATHER FORECASTING:  [1.00000000e+00 1.00000000e+00 0.00000000e+00 4.40000010e+00\n",
      " 6.50000000e+01 3.87500000e+00 1.45000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.28000002e+01 4.00000000e+01 1.99520779e+01\n",
      " 2.82156696e+01 0.00000000e+00 0.00000000e+00 1.17947556e+02\n",
      " 1.06152805e+05]\n",
      "\u001b[38;20m[WRAPPER WeatherForecastingWrapper] (INFO) : Wrapper initialized.\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#      \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m                                         \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 2: Eplus-5zone-hot-discrete-v1\u001b[0m                          \n",
      "#----------------------------------------------------------------------------------------------#   \n",
      "\u001b[38;20m[MODEL] (INFO) : Episode directory created.\u001b[0m                                            \n",
      "\u001b[38;20m[MODEL] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m           \n",
      "\u001b[38;20m[MODEL] (INFO) : Adapting weather to building model.\u001b[0m                                   \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path in /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1/episode-2/output.\u001b[0m\n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:00<00:00, 476.89%/s, 100% completed]\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 2 started.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Original environment\n",
    "env = gym.make('Eplus-5zone-hot-discrete-v1')\n",
    "obs, info = env.reset()\n",
    "print('OBSERVATION VARIABLES BEFORE WEATHER FORECASTING: ',\n",
    "      env.get_wrapper_attr('observation_variables'))\n",
    "print('OBSERVATION BEFORE WEATHER FORECASTING: ', obs)\n",
    "\n",
    "# Weather forecasting environment\n",
    "env = WeatherForecastingWrapper(env, n=5, delta=1)\n",
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBSERVATION VARIABLES AFTER WEATHER FORECASTING:  ['month', 'day_of_month', 'hour', 'outdoor_temperature', 'outdoor_humidity', 'wind_speed', 'wind_direction', 'diffuse_solar_radiation', 'direct_solar_radiation', 'htg_setpoint', 'clg_setpoint', 'air_temperature', 'air_humidity', 'people_occupant', 'co2_emission', 'HVAC_electricity_demand_rate', 'total_electricity_HVAC', 'forecast_1_Dry Bulb Temperature', 'forecast_1_Relative Humidity', 'forecast_1_Wind Direction', 'forecast_1_Wind Speed', 'forecast_1_Direct Normal Radiation', 'forecast_1_Diffuse Horizontal Radiation', 'forecast_2_Dry Bulb Temperature', 'forecast_2_Relative Humidity', 'forecast_2_Wind Direction', 'forecast_2_Wind Speed', 'forecast_2_Direct Normal Radiation', 'forecast_2_Diffuse Horizontal Radiation', 'forecast_3_Dry Bulb Temperature', 'forecast_3_Relative Humidity', 'forecast_3_Wind Direction', 'forecast_3_Wind Speed', 'forecast_3_Direct Normal Radiation', 'forecast_3_Diffuse Horizontal Radiation', 'forecast_4_Dry Bulb Temperature', 'forecast_4_Relative Humidity', 'forecast_4_Wind Direction', 'forecast_4_Wind Speed', 'forecast_4_Direct Normal Radiation', 'forecast_4_Diffuse Horizontal Radiation', 'forecast_5_Dry Bulb Temperature', 'forecast_5_Relative Humidity', 'forecast_5_Wind Direction', 'forecast_5_Wind Speed', 'forecast_5_Direct Normal Radiation', 'forecast_5_Diffuse Horizontal Radiation']\n",
      "OBSERVATION AFTER WEATHER FORECASTING:  [1.00000000e+00 1.00000000e+00 0.00000000e+00 4.40000010e+00\n",
      " 6.50000000e+01 3.87500000e+00 1.45000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.28000002e+01 4.00000000e+01 1.99520779e+01\n",
      " 2.82156696e+01 0.00000000e+00 0.00000000e+00 1.17947556e+02\n",
      " 1.06152805e+05 4.60000000e+00 5.80000000e+01 2.00000000e+02\n",
      " 5.60000000e+00 0.00000000e+00 0.00000000e+00 3.70000000e+00\n",
      " 6.40000000e+01 1.50000000e+02 4.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.20000000e+00 7.00000000e+01 1.40000000e+02\n",
      " 3.00000000e+00 0.00000000e+00 0.00000000e+00 1.20000000e+00\n",
      " 7.40000000e+01 2.10000000e+02 2.90000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 8.00000000e-01 7.80000000e+01 2.10000000e+02\n",
      " 2.40000000e+00 0.00000000e+00 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print('OBSERVATION VARIABLES AFTER WEATHER FORECASTING: ',\n",
    "      env.get_wrapper_attr('observation_variables'))\n",
    "\n",
    "print('OBSERVATION AFTER WEATHER FORECASTING: ', obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy cost wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wrapper adds energy cost information to the current observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Name: Eplus-5zone-hot-discrete-v1\u001b[0m\n",
      "#==============================================================================================#\n",
      "\u001b[38;20m[MODEL] (INFO) : Working directory created: /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Model Config is correct.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Building model Output:Variable updated with defined variable names.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Updated building model Output:Meter with meter names.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Runperiod established.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : timesteps per episode: 35040\u001b[0m\n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment created successfully.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : New Discrete Space and mapping: Discrete(10)\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Make sure that the action space is compatible and contained in the original environment.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscretizeEnv] (INFO) : Wrapper initialized\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1: Eplus-5zone-hot-discrete-v1\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode directory created.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Adapting weather to building model.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path in /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1/episode-1/output.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
      "OBSERVATION VARIABLES BEFORE ADDING ENERGY COST: \n",
      " ['month', 'day_of_month', 'hour', 'outdoor_temperature', 'outdoor_humidity', 'wind_speed', 'wind_direction', 'diffuse_solar_radiation', 'direct_solar_radiation', 'htg_setpoint', 'clg_setpoint', 'air_temperature', 'air_humidity', 'people_occupant', 'co2_emission', 'HVAC_electricity_demand_rate', 'total_electricity_HVAC']\n",
      "OBSERVATION VALUES BEFORE ADDING ENERGY COST: \n",
      " [1.00000000e+00 1.00000000e+00 0.00000000e+00 4.40000010e+00\n",
      " 6.50000000e+01 3.87500000e+00 1.45000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.28000002e+01 4.00000000e+01 1.99520779e+01\n",
      " 2.82156696e+01 0.00000000e+00 0.00000000e+00 1.17947556e+02\n",
      " 1.06152805e+05]\n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m\n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER EnergyCostWrapper] (INFO) : Wrapper initialized.\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#      \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m                                         \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 2: Eplus-5zone-hot-discrete-v1\u001b[0m                          \n",
      "#----------------------------------------------------------------------------------------------#   \n",
      "\u001b[38;20m[MODEL] (INFO) : Episode directory created.\u001b[0m                                            \n",
      "\u001b[38;20m[MODEL] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m           \n",
      "\u001b[38;20m[MODEL] (INFO) : Adapting weather to building model.\u001b[0m                                   \n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path in /workspaces/sinergym/examples/Eplus-5zone-hot-discrete-v1-res1/episode-2/output.\u001b[0m\n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:00<00:00, 471.24%/s, 100% completed]\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 2 started.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Original environment\n",
    "env = gym.make('Eplus-5zone-hot-discrete-v1')\n",
    "obs, info = env.reset()\n",
    "print('OBSERVATION VARIABLES BEFORE ADDING ENERGY COST: \\n',\n",
    "      env.get_wrapper_attr('observation_variables'))\n",
    "print('OBSERVATION VALUES BEFORE ADDING ENERGY COST: \\n', obs)\n",
    "\n",
    "# Energy Cost environment\n",
    "env = EnergyCostWrapper(\n",
    "    env, energy_cost_data_path='/workspaces/sinergym/sinergym/data/energy_cost/PVPC_active_energy_billing_Iberian_Peninsula_2023.csv')\n",
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBSERVATION VARIABLES AFTER ADDING ENERGY COST: \n",
      " ['month', 'day_of_month', 'hour', 'outdoor_temperature', 'outdoor_humidity', 'wind_speed', 'wind_direction', 'diffuse_solar_radiation', 'direct_solar_radiation', 'htg_setpoint', 'clg_setpoint', 'air_temperature', 'air_humidity', 'people_occupant', 'co2_emission', 'HVAC_electricity_demand_rate', 'total_electricity_HVAC', 'energy_cost']\n",
      "OBSERVATION VALUES AFTER ADDING ENERGY COST: \n",
      " [1.00000000e+00 1.00000000e+00 0.00000000e+00 4.40000010e+00\n",
      " 6.50000000e+01 3.87500000e+00 1.45000000e+02 0.00000000e+00\n",
      " 0.00000000e+00 1.28000002e+01 4.00000000e+01 1.99520779e+01\n",
      " 2.82156696e+01 0.00000000e+00 0.00000000e+00 1.17947556e+02\n",
      " 1.06152805e+05 4.14500000e+01]\n"
     ]
    }
   ],
   "source": [
    "print('OBSERVATION VARIABLES AFTER ADDING ENERGY COST: \\n', env.get_wrapper_attr('observation_variables'))\n",
    "print('OBSERVATION VALUES AFTER ADDING ENERGY COST: \\n',obs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesting wrappers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All wrappers included in *Sinergym* are stackable and organized in layers. However, the order in which these layers are applied can affect the final result, depending on the wrappers being used.\n",
    "\n",
    "For instance, applying the logger before normalizing differs from doing it in the reverse order. In the first case, the data will be logged without normalization, even though the agent will operate in a normalized environment. In the second case, the logger will capture the normalized values since it encapsulates the normalization applied by the previous layer.\n",
    "\n",
    "An example of how to nest wrappers is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Name: Eplus-5zone-hot-continuous-v1\u001b[0m\n",
      "#==============================================================================================#\n",
      "\u001b[38;20m[MODEL] (INFO) : Working directory created: /workspaces/sinergym/examples/Eplus-5zone-hot-continuous-v1-res1\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Model Config is correct.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Building model Output:Variable updated with defined variable names.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Updated building model Output:Meter with meter names.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Runperiod established.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : timesteps per episode: 35040\u001b[0m\n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment created successfully.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER MultiObjectiveReward] (INFO) : wrapper initialized.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER PreviousObservationWrapper] (INFO) : Wrapper initialized.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DatetimeWrapper] (INFO) : Wrapper initialized.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscreteIncrementalWrapper] (INFO) : New incremental action mapping: 17\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscreteIncrementalWrapper] (INFO) : {0: array([0., 0.], dtype=float32), 1: array([0.5, 0. ], dtype=float32), 2: array([1., 0.], dtype=float32), 3: array([1.5, 0. ], dtype=float32), 4: array([2., 0.], dtype=float32), 5: array([-0.5,  0. ], dtype=float32), 6: array([-1.,  0.], dtype=float32), 7: array([-1.5,  0. ], dtype=float32), 8: array([-2.,  0.], dtype=float32), 9: array([0. , 0.5], dtype=float32), 10: array([0., 1.], dtype=float32), 11: array([0. , 1.5], dtype=float32), 12: array([0., 2.], dtype=float32), 13: array([ 0. , -0.5], dtype=float32), 14: array([ 0., -1.], dtype=float32), 15: array([ 0. , -1.5], dtype=float32), 16: array([ 0., -2.], dtype=float32)}\u001b[0m\n",
      "\u001b[38;20m[WRAPPER DiscreteIncrementalWrapper] (INFO) : Wrapper initialized\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Wrapper initialized.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER LoggerWrapper] (INFO) : Wrapper initialized.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER MultiObsWrapper] (INFO) : Wrapper initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Eplus-5zone-hot-continuous-v1')\n",
    "env = MultiObjectiveReward(\n",
    "    env=env,\n",
    "    reward_terms=[\n",
    "        'energy_term',\n",
    "        'comfort_term'])\n",
    "env = PreviousObservationWrapper(env, previous_variables=[\n",
    "    'htg_setpoint',\n",
    "    'clg_setpoint',\n",
    "    'air_temperature'])\n",
    "env = DatetimeWrapper(env)\n",
    "env = DiscreteIncrementalWrapper(\n",
    "    env, initial_values=[21.0, 25.0], delta_temp=2, step_temp=0.5)\n",
    "env = NormalizeObservation(\n",
    "    env=env)\n",
    "env = LoggerWrapper(env=env)\n",
    "env = MultiObsWrapper(env=env, n=5, flatten=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we can simply use the wrapped environment as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1: Eplus-5zone-hot-continuous-v1\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODEL] (INFO) : Episode directory created.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODEL] (INFO) : Adapting weather to building model.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path in /workspaces/sinergym/examples/Eplus-5zone-hot-continuous-v1-res1/episode-1/output.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
      "Reward:  [-0.48383429007956374, 0.0] {'time_elapsed(hours)': 0.5416666666666666, 'month': 1, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [21.0, 23.25], 'timestep': 1, 'reward': -0.48383429007956374, 'energy_term': -0.48383429007956374, 'comfort_term': 0.0, 'energy_penalty': -9676.685801591275, 'comfort_penalty': 0, 'total_power_demand': 9676.685801591275, 'total_temperature_violation': 0, 'reward_weight': 0.5}\n",
      "Simulation Progress [Episode 1]:  10%|█         | 10/100 [00:01<00:17,  5.23%/s, 10% completed]  Reward:  [-0.005897377870609513, 0.0] {'time_elapsed(hours)': 744.25, 'month': 2, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [13.75, 27.75], 'timestep': 2976, 'reward': -0.005897377870609513, 'energy_term': -0.005897377870609513, 'comfort_term': 0.0, 'energy_penalty': -117.94755741219025, 'comfort_penalty': 0, 'total_power_demand': 117.94755741219025, 'total_temperature_violation': 0, 'reward_weight': 0.5}\n",
      "Simulation Progress [Episode 1]:  17%|█▋        | 17/100 [00:02<00:14,  5.88%/s, 17% completed]Reward:  [-0.005897377870609513, 0.0] {'time_elapsed(hours)': 1416.25, 'month': 3, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [12.75, 26.0], 'timestep': 5664, 'reward': -0.005897377870609513, 'energy_term': -0.005897377870609513, 'comfort_term': 0.0, 'energy_penalty': -117.94755741219025, 'comfort_penalty': 0, 'total_power_demand': 117.94755741219025, 'total_temperature_violation': 0, 'reward_weight': 0.5}\n",
      "Simulation Progress [Episode 1]:  26%|██▌       | 26/100 [00:04<00:14,  5.07%/s, 26% completed]Reward:  [-0.005897377870609513, 0.0] {'time_elapsed(hours)': 2160.25, 'month': 4, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [17.25, 23.25], 'timestep': 8640, 'reward': -0.005897377870609513, 'energy_term': -0.005897377870609513, 'comfort_term': 0.0, 'energy_penalty': -117.94755741219025, 'comfort_penalty': 0, 'total_power_demand': 117.94755741219025, 'total_temperature_violation': 0, 'reward_weight': 0.5}\n",
      "Simulation Progress [Episode 1]:  34%|███▍      | 34/100 [00:06<00:14,  4.50%/s, 34% completed]Reward:  [-0.08878907070147038, 0.0] {'time_elapsed(hours)': 2880.25, 'month': 5, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [23.25, 28.0], 'timestep': 11520, 'reward': -0.08878907070147038, 'energy_term': -0.08878907070147038, 'comfort_term': 0.0, 'energy_penalty': -1775.7814140294076, 'comfort_penalty': 0, 'total_power_demand': 1775.7814140294076, 'total_temperature_violation': 0, 'reward_weight': 0.5}\n",
      "Simulation Progress [Episode 1]:  42%|████▏     | 42/100 [00:08<00:13,  4.19%/s, 42% completed]Reward:  [-0.03912978501610814, -0.08803840086374848] {'time_elapsed(hours)': 3624.25, 'month': 6, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [20.75, 24.25], 'timestep': 14496, 'reward': -0.12716818587985662, 'energy_term': -0.03912978501610814, 'comfort_term': -0.08803840086374848, 'energy_penalty': -782.5957003221629, 'comfort_penalty': -0.17607680172749696, 'total_power_demand': 782.5957003221629, 'total_temperature_violation': 0.17607680172749696, 'reward_weight': 0.5}\n",
      "Simulation Progress [Episode 1]:  51%|█████     | 51/100 [00:10<00:11,  4.21%/s, 51% completed]Reward:  [-0.03708112087791508, 0.0] {'time_elapsed(hours)': 4344.25, 'month': 7, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [23.25, 26.0], 'timestep': 17376, 'reward': -0.03708112087791508, 'energy_term': -0.03708112087791508, 'comfort_term': 0.0, 'energy_penalty': -741.6224175583017, 'comfort_penalty': 0, 'total_power_demand': 741.6224175583017, 'total_temperature_violation': 0, 'reward_weight': 0.5}\n",
      "Simulation Progress [Episode 1]:  59%|█████▉    | 59/100 [00:12<00:08,  4.62%/s, 59% completed]Reward:  [-0.06671566172639565, 0.0] {'time_elapsed(hours)': 5088.25, 'month': 8, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [23.25, 23.75], 'timestep': 20352, 'reward': -0.06671566172639565, 'energy_term': -0.06671566172639565, 'comfort_term': 0.0, 'energy_penalty': -1334.3132345279128, 'comfort_penalty': 0, 'total_power_demand': 1334.3132345279128, 'total_temperature_violation': 0, 'reward_weight': 0.5}\n",
      "Simulation Progress [Episode 1]:  67%|██████▋   | 67/100 [00:14<00:07,  4.65%/s, 67% completed]Reward:  [-0.03010492807075567, -0.21086620795861855] {'time_elapsed(hours)': 5832.25, 'month': 9, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [13.5, 26.25], 'timestep': 23328, 'reward': -0.24097113602937423, 'energy_term': -0.03010492807075567, 'comfort_term': -0.21086620795861855, 'energy_penalty': -602.0985614151134, 'comfort_penalty': -0.4217324159172371, 'total_power_demand': 602.0985614151134, 'total_temperature_violation': 0.4217324159172371, 'reward_weight': 0.5}\n",
      "Simulation Progress [Episode 1]:  76%|███████▌  | 76/100 [00:16<00:05,  4.45%/s, 76% completed]Reward:  [-0.03751588574194862, 0.0] {'time_elapsed(hours)': 6552.25, 'month': 10, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [12.25, 28.0], 'timestep': 26208, 'reward': -0.03751588574194862, 'energy_term': -0.03751588574194862, 'comfort_term': 0.0, 'energy_penalty': -750.3177148389724, 'comfort_penalty': 0, 'total_power_demand': 750.3177148389724, 'total_temperature_violation': 0, 'reward_weight': 0.5}\n",
      "Simulation Progress [Episode 1]:  84%|████████▍ | 84/100 [00:17<00:02,  5.39%/s, 84% completed]Reward:  [-0.005897377870609513, 0.0] {'time_elapsed(hours)': 7296.25, 'month': 11, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [20.0, 29.5], 'timestep': 29184, 'reward': -0.005897377870609513, 'energy_term': -0.005897377870609513, 'comfort_term': 0.0, 'energy_penalty': -117.94755741219025, 'comfort_penalty': 0, 'total_power_demand': 117.94755741219025, 'total_temperature_violation': 0, 'reward_weight': 0.5}\n",
      "Simulation Progress [Episode 1]:  92%|█████████▏| 92/100 [00:19<00:01,  4.78%/s, 92% completed]Reward:  [-0.005897377870609513, 0.0] {'time_elapsed(hours)': 8016.25, 'month': 12, 'day': 1, 'hour': 0, 'is_raining': False, 'action': [12.5, 26.0], 'timestep': 32064, 'reward': -0.005897377870609513, 'energy_term': -0.005897377870609513, 'comfort_term': 0.0, 'energy_penalty': -117.94755741219025, 'comfort_penalty': 0, 'total_power_demand': 117.94755741219025, 'total_temperature_violation': 0, 'reward_weight': 0.5}\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Normalization calibration saved.\u001b[0m             \n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:23<00:00,  4.30%/s, 100% completed]\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [Eplus-5zone-hot-continuous-v1]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    obs, info = env.reset()\n",
    "    truncated = terminated = False\n",
    "    current_month = 0\n",
    "    while not (terminated or truncated):\n",
    "        a = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, info = env.step(a)\n",
    "        if info['month'] != current_month:  # display results every month\n",
    "            current_month = info['month']\n",
    "            print('Reward: ', reward, info)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
