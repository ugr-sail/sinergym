{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Rule Controller example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First, we import all the necessary libraries. Remember to always import `sinergym`, even if it appears unused, as it's needed to define the environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import List, Any, Sequence\n",
    "from sinergym.utils.constants import YEAR\n",
    "from datetime import datetime\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import sinergym"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Next, we can define the environment we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Name: 5zone-hot-continuous-v1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#\n",
      "\u001b[38;20m[MODELING] (INFO) : Experiment working directory created.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Working directory: /workspaces/sinergym/examples/Eplus-env-5zone-hot-continuous-v1-res1\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Model Config is correct.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Update building model Output:Variable with variable names.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Update building model Output:Meter with meter names.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Runperiod established.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : timesteps per episode: 35040\u001b[0m\n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment created successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Eplus-5zone-hot-continuous-v1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For the Rule-based controller, check out the already defined controllers. There's one for each building. We're extending that controller and defining the action function we want. Feel free to modify the function to define your own action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sinergym.utils.controllers import RBC5Zone\n",
    "\n",
    "class MyRuleBasedController(RBC5Zone):\n",
    "\n",
    "    def act(self, observation: List[Any]) -> Sequence[Any]:\n",
    "        \"\"\"Select action based on outdoor air drybulb temperature and daytime.\n",
    "\n",
    "        Args:\n",
    "            observation (List[Any]): Perceived observation.\n",
    "\n",
    "        Returns:\n",
    "            Sequence[Any]: Action chosen.\n",
    "        \"\"\"\n",
    "        obs_dict = dict(zip(self.env.get_wrapper_attr('observation_variables'), observation))\n",
    "\n",
    "        out_temp = obs_dict['outdoor_temperature']\n",
    "\n",
    "        day = int(obs_dict['day_of_month'])\n",
    "        month = int(obs_dict['month'])\n",
    "        hour = int(obs_dict['hour'])\n",
    "        year = int(obs_dict['year'] if obs_dict.get('year',False) else YEAR)\n",
    "\n",
    "        summer_start_date = datetime(year, 6, 1)\n",
    "        summer_final_date = datetime(year, 9, 30)\n",
    "\n",
    "        current_dt = datetime(year, month, day)\n",
    "\n",
    "        # Get season comfort range\n",
    "        if current_dt >= summer_start_date and current_dt <= summer_final_date:\n",
    "            season_comfort_range = self.setpoints_summer\n",
    "        else:\n",
    "            season_comfort_range = self.setpoints_summer\n",
    "        season_comfort_range = self.setpoints_winter\n",
    "        # Update setpoints\n",
    "        in_temp = obs_dict['air_temperature']\n",
    "\n",
    "        current_heat_setpoint = obs_dict[\n",
    "            'htg_setpoint']\n",
    "        current_cool_setpoint = obs_dict[\n",
    "            'clg_setpoint']\n",
    "\n",
    "        new_heat_setpoint = current_heat_setpoint\n",
    "        new_cool_setpoint = current_cool_setpoint\n",
    "\n",
    "        if in_temp < season_comfort_range[0]:\n",
    "            new_heat_setpoint = current_heat_setpoint + 1\n",
    "            new_cool_setpoint = current_cool_setpoint + 1\n",
    "        elif in_temp > season_comfort_range[1]:\n",
    "            new_cool_setpoint = current_cool_setpoint - 1\n",
    "            new_heat_setpoint = current_heat_setpoint - 1\n",
    "\n",
    "        #Clip setpoints to the action space\n",
    "        if new_heat_setpoint>self.env.get_wrapper_attr('action_space').high[0]:\n",
    "            new_heat_setpoint=self.env.get_wrapper_attr('action_space').high[0]\n",
    "        if new_heat_setpoint<self.env.get_wrapper_attr('action_space').low[0]:\n",
    "            new_heat_setpoint=self.env.get_wrapper_attr('action_space').low[0]\n",
    "        if new_cool_setpoint>self.env.get_wrapper_attr('action_space').high[1]:\n",
    "            new_cool_setpoint=self.env.get_wrapper_attr('action_space').high[1]\n",
    "        if new_cool_setpoint<self.env.get_wrapper_attr('action_space').low[1]:\n",
    "            new_cool_setpoint=self.env.get_wrapper_attr('action_space').low[1]\n",
    "\n",
    "        action = (new_heat_setpoint, new_cool_setpoint)\n",
    "        if current_dt.weekday() > 5 or hour in range(22, 6):\n",
    "            #weekend or night\n",
    "            action = (18.33, 23.33)\n",
    "\n",
    "        return action"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that our controller is ready, we can use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1: 5zone-hot-continuous-v1\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode directory created.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Adapting weather to building model.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "Reward:  -0.10122987987606541 {'time_elapsed(hours)': 0.5, 'month': 1, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(13.8), np.float32(30.0)), 'timestep': 1, 'reward': -0.10122987987606541, 'energy_term': -0.00589738497079933, 'comfort_term': -0.09533249490526607, 'reward_weight': 0.5, 'abs_energy_penalty': -117.9476994159866, 'abs_comfort_penalty': -0.19066498981053215, 'total_power_demand': 117.9476994159866, 'total_temperature_violation': 0.19066498981053215}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/gymnasium/spaces/box.py:240: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "  gym.logger.warn(\"Casting input x to numpy array.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation Progress [Episode 1]:  10%|█         | 10/100 [00:00<00:09,  9.64%/s, 10% completed] Reward:  -500.8158604654543 {'time_elapsed(hours)': 744.25, 'month': 2, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 2976, 'reward': -0.00589738497079933, 'energy_term': -0.00589738497079933, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -117.9476994159866, 'abs_comfort_penalty': 0, 'total_power_demand': 117.9476994159866, 'total_temperature_violation': 0.0}\n",
      "Simulation Progress [Episode 1]:  17%|█▋        | 17/100 [00:01<00:08,  9.88%/s, 17% completed]Reward:  -771.2477959705227 {'time_elapsed(hours)': 1416.25, 'month': 3, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 5664, 'reward': -0.00589738497079933, 'energy_term': -0.00589738497079933, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -117.9476994159866, 'abs_comfort_penalty': 0, 'total_power_demand': 117.9476994159866, 'total_temperature_violation': 0.0}\n",
      "Simulation Progress [Episode 1]:  26%|██▌       | 26/100 [00:02<00:06, 11.30%/s, 26% completed]Reward:  -1099.6675505462101 {'time_elapsed(hours)': 2160.25, 'month': 4, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (18.33, 23.33), 'timestep': 8640, 'reward': -0.00589738497079933, 'energy_term': -0.00589738497079933, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -117.9476994159866, 'abs_comfort_penalty': 0, 'total_power_demand': 117.9476994159866, 'total_temperature_violation': 0.0}\n",
      "Simulation Progress [Episode 1]:  34%|███▍      | 34/100 [00:03<00:06,  9.53%/s, 34% completed]Reward:  -1443.9892728462598 {'time_elapsed(hours)': 2880.25, 'month': 5, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 11520, 'reward': -0.00986244334034497, 'energy_term': -0.00986244334034497, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -197.24886680689937, 'abs_comfort_penalty': 0, 'total_power_demand': 197.24886680689937, 'total_temperature_violation': 0.0}\n",
      "Simulation Progress [Episode 1]:  42%|████▏     | 42/100 [00:04<00:06,  9.08%/s, 42% completed]Reward:  -1850.3837512878513 {'time_elapsed(hours)': 3624.25, 'month': 6, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 14496, 'reward': -0.443418973577729, 'energy_term': -0.03306759297397215, 'comfort_term': -0.41035138060375687, 'reward_weight': 0.5, 'abs_energy_penalty': -661.351859479443, 'abs_comfort_penalty': -0.8207027612075137, 'total_power_demand': 661.351859479443, 'total_temperature_violation': 0.8207027612075137}\n",
      "Simulation Progress [Episode 1]:  51%|█████     | 51/100 [00:05<00:04, 11.44%/s, 51% completed]Reward:  -2994.821084822717 {'time_elapsed(hours)': 4344.25, 'month': 7, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (18.33, 23.33), 'timestep': 17376, 'reward': -0.2168368480281406, 'energy_term': -0.03331450494007778, 'comfort_term': -0.1835223430880628, 'reward_weight': 0.5, 'abs_energy_penalty': -666.2900988015556, 'abs_comfort_penalty': -0.3670446861761256, 'total_power_demand': 666.2900988015556, 'total_temperature_violation': 0.3670446861761256}\n",
      "Simulation Progress [Episode 1]:  59%|█████▉    | 59/100 [00:06<00:04,  8.89%/s, 59% completed]Reward:  -4192.843264700024 {'time_elapsed(hours)': 5088.25, 'month': 8, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 20352, 'reward': -0.4444265580218612, 'energy_term': -0.03655451169123719, 'comfort_term': -0.407872046330624, 'reward_weight': 0.5, 'abs_energy_penalty': -731.0902338247438, 'abs_comfort_penalty': -0.815744092661248, 'total_power_demand': 731.0902338247438, 'total_temperature_violation': 0.815744092661248}\n",
      "Simulation Progress [Episode 1]:  67%|██████▋   | 67/100 [00:06<00:02, 11.54%/s, 67% completed]Reward:  -5380.941330999556 {'time_elapsed(hours)': 5832.25, 'month': 9, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 23328, 'reward': -0.2973068555116624, 'energy_term': -0.02993733348744081, 'comfort_term': -0.2673695220242216, 'reward_weight': 0.5, 'abs_energy_penalty': -598.7466697488162, 'abs_comfort_penalty': -0.5347390440484432, 'total_power_demand': 598.7466697488162, 'total_temperature_violation': 0.5347390440484432}\n",
      "Simulation Progress [Episode 1]:  76%|███████▌  | 76/100 [00:07<00:02, 10.25%/s, 76% completed]Reward:  -6627.123778199568 {'time_elapsed(hours)': 6552.25, 'month': 10, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 26208, 'reward': -0.03177037793883851, 'energy_term': -0.03177037793883851, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -635.4075587767702, 'abs_comfort_penalty': 0, 'total_power_demand': 635.4075587767702, 'total_temperature_violation': 0.0}\n",
      "Simulation Progress [Episode 1]:  84%|████████▍ | 84/100 [00:08<00:01, 11.03%/s, 84% completed]Reward:  -6944.464641871541 {'time_elapsed(hours)': 7296.25, 'month': 11, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 29184, 'reward': -0.00589738497079933, 'energy_term': -0.00589738497079933, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -117.9476994159866, 'abs_comfort_penalty': 0, 'total_power_demand': 117.9476994159866, 'total_temperature_violation': 0.0}\n",
      "Simulation Progress [Episode 1]:  92%|█████████▏| 92/100 [00:09<00:00, 10.92%/s, 92% completed]Reward:  -7259.377698005483 {'time_elapsed(hours)': 8016.25, 'month': 12, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (np.float32(18.33), np.float32(23.33)), 'timestep': 32064, 'reward': -0.018698130195533794, 'energy_term': -0.018698130195533794, 'comfort_term': 0.0, 'reward_weight': 0.5, 'abs_energy_penalty': -373.96260391067585, 'abs_comfort_penalty': 0, 'total_power_demand': 373.96260391067585, 'total_temperature_violation': 0.0}\n",
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:09<00:00, 11.14%/s, 100% completed]Episode  0 Mean reward:  -0.21907941002188872 Cumulative reward:  -7676.542527166982\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create rule-based controller\n",
    "agent = MyRuleBasedController(env)\n",
    "\n",
    "for i in range(1):\n",
    "    obs, info = env.reset()\n",
    "    rewards = []\n",
    "    truncated = terminated = False\n",
    "    current_month = 0\n",
    "while not (terminated or truncated):\n",
    "    action = agent.act(obs)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    rewards.append(reward)\n",
    "    if info['month'] != current_month:  # display results every month\n",
    "        current_month = info['month']\n",
    "        print('Reward: ', sum(rewards), info)\n",
    "print(\n",
    "    'Episode ',\n",
    "    i,\n",
    "    'Mean reward: ',\n",
    "    np.mean(rewards),\n",
    "    'Cumulative reward: ',\n",
    "    sum(rewards))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Always remember to close the environment when you're done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation Progress [Episode 1]: 100%|██████████| 100/100 [00:12<00:00,  8.33%/s, 100% completed]\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [5zone-hot-continuous-v1]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about our defined controllers and how to create a new one, please visit our [Controller Documentation](https://ugr-sail.github.io/sinergym/compilation/main/pages/controllers.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
