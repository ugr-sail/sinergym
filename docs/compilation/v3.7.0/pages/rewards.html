<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Rewards &mdash; Sinergym  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/doc_theme.css?v=642ef2a8" />

  
    <link rel="shortcut icon" href="../_static/logo-sidebar.png"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../_static/doctools.js?v=9a2dae69"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Controllers" href="controllers.html" />
    <link rel="prev" title="Sinergym output" href="output.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #a5beba" >

          
          
          <a href="../index.html" class="icon icon-home">
            Sinergym
              <img src="../_static/logo-sidebar.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage-example.html">Usage example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Sinergym</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="buildings.html">Buildings</a></li>
<li class="toctree-l1"><a class="reference internal" href="weathers.html">Weathers</a></li>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="environments.html">Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="environments_registration.html">Environments configuration and registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging system overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="output.html">Sinergym output</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Rewards</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#reward-terms">Reward terms</a></li>
<li class="toctree-l2"><a class="reference internal" href="#custom-rewards">Custom rewards</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="controllers.html">Controllers</a></li>
<li class="toctree-l1"><a class="reference internal" href="wrappers.html">Wrappers</a></li>
<li class="toctree-l1"><a class="reference internal" href="extra-configuration.html">Extra configuration in Sinergym simulations</a></li>
<li class="toctree-l1"><a class="reference internal" href="deep-reinforcement-learning.html">Deep Reinforcement Learning integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="gcloudAPI.html">Google Cloud integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="github-actions.html">Github actions</a></li>
<li class="toctree-l1"><a class="reference internal" href="tests.html">Tests</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notebooks/basic_example.html">Basic example</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/getting_env_information.html">Getting information about Sinergym environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/sinergym_package.html">Sinergym package information</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/change_environment.html">Changing an environment registered in Sinergym</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/default_building_control.html">Default building control using an empty action space</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/wrappers_examples.html">Wrappers example</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/personalize_loggerwrapper.html">LoggerWrapper customization</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/logging_unused_variables.html">Logging unused variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/rule_controller_example.html">Rule-based controller example</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/drl.html">DRL usage example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="API-reference.html">API reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #a5beba" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Sinergym</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Rewards</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/pages/rewards.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="rewards">
<h1>Rewards<a class="headerlink" href="#rewards" title="Link to this heading">ÔÉÅ</a></h1>
<p>The definition of a reward function is essential for reinforcement learning. For this reason, <em>Sinergym</em> allows you to use pre-implemented reward functions or to create custom ones.</p>
<p>The predefined reward functions in <em>Sinergym</em> are designed as multi-objective, incorporating both <strong>energy consumption</strong> and <strong>thermal discomfort</strong>. These are <strong>normalised</strong> and added with varying <strong>weights</strong>. The assigned weights for each term in the reward function enable the importance of each reward component to be adjusted.</p>
<p>It should be noted that pre implemented rewards are expressed in <strong>negative</strong> terms, signifying that optimal behavior results in a cumulative reward of 0. Separate temperature comfort ranges are defined for summer and winter periods.</p>
<p>The most basic definition of the reward signal in <em>Sinergym</em> consists of the following equation:</p>
<div class="math notranslate nohighlight">
\[r_t = - \omega \ \lambda_P \ P_t - (1 - \omega) \ \lambda_T \ (|T_t - T_{up}| + |T_t - T_{low}|)\]</div>
<p>Where: <br /></p>
<p><span class="math notranslate nohighlight">\(P_t\)</span> represents power consumption, <br />
<span class="math notranslate nohighlight">\(T_t\)</span> is the current indoor temperature, <br />
<span class="math notranslate nohighlight">\(T_{up}\)</span> and <span class="math notranslate nohighlight">\(T_{low}\)</span> are the upper and lower comfort range limits, respectively, <br />
<span class="math notranslate nohighlight">\(\omega\)</span> is the weight assigned to power consumption, and consequently, <span class="math notranslate nohighlight">\(1 - \omega\)</span> represents the comfort weight, <br />
<span class="math notranslate nohighlight">\(\lambda_P\)</span> and <span class="math notranslate nohighlight">\(\lambda_T\)</span> are scaling constants for consumption and comfort penalties, respectively.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The constants <span class="math notranslate nohighlight">\(\lambda_P\)</span> and <span class="math notranslate nohighlight">\(\lambda_T\)</span> are configured to create a proportional
relationship between energy and comfort penalties, with the objective of calibrating their magnitudes.
It is essential to adjust these constants when working with different buildings to ensure that the magnitude of both reward parts remains consistent.</p>
</div>
<p>Different types of reward functions are already pre-defined in <em>Sinergym</em>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">LinearReward</span></code>: implements a <strong>linear reward</strong> function, where discomfort is calculated as the absolute
difference between the current temperature and the comfort range.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ExpReward</span></code>: similar to the linear reward, but calculates discomfort using the <strong>exponential difference</strong>
between the current temperature and comfort ranges, resulting in a higher penalty for larger deviations
from target temperatures.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">HourlyLinearReward</span></code>: adjusts the weight assigned to discomfort based on the <strong>hour of the day</strong>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">NormalizedLinearReward</span></code>: normalizes the reward components based on the maximum energy and comfort penalties. It is calculated using a moving average, and the <span class="math notranslate nohighlight">\(\lambda_P\)</span> and <span class="math notranslate nohighlight">\(\lambda_T\)</span> constants are not required to calibrate both magnitudes.</p></li>
</ul>
<blockquote>
<div><div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This reward function improves in accuracy as the simulation progresses, but is less accurate in the early stages when it is not yet balanced.</p>
</div>
</div></blockquote>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">EnergyCostLinearReward</span></code>: is a linear reward function which includes an <strong>energy cost</strong> term:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[r_t = - \omega_P \ \lambda_P \ P_t - \omega_T \ \lambda_T \ (|T_t - T_{up}| + |T_t - T_{low}|) - (1 - \omega_P - \omega_T) \ \lambda_{EC} \ EC_t\]</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This function is used internally by the <a class="reference internal" href="wrappers.html#energycostwrapper"><span class="std std-ref">EnergyCostWrapper</span></a> and it is not intended to be used otherwise.</p>
</div>
</div></blockquote>
</li>
</ul>
<p>It should be noted that the reward functions have parameters in their constructors, the values of which may vary based on the building used or other factors. The default setting is the <code class="docutils literal notranslate"><span class="pre">LinearReward</span></code> function with the standard parameters for each building. Please refer to the example in <a class="reference internal" href="notebooks/change_environment.html#Adding-a-new-reward"><span class="std std-ref">Adding a new reward</span></a> for further details on how to define custom rewards.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When specifying a reward other than the default reward for a given environment ID, it is necessary to specify the
<code class="docutils literal notranslate"><span class="pre">reward_kwargs</span></code> when calling <code class="docutils literal notranslate"><span class="pre">gym.make</span></code>.</p>
</div>
<section id="reward-terms">
<h2>Reward terms<a class="headerlink" href="#reward-terms" title="Link to this heading">ÔÉÅ</a></h2>
<p>By default, reward functions return a <strong>scalar value</strong> and the values of the <strong>terms</strong> involved in its calculation. The values of these terms depend on the specific reward function used and are automatically added to the environment‚Äôs <code class="docutils literal notranslate"><span class="pre">info</span></code> dictionary.</p>
<p>The reward structure generally matches the diagram below:</p>
<a class="reference internal image-reference" href="../_images/reward_terms.png"><img alt="Reward terms" class="align-center" src="../_images/reward_terms.png" style="width: 1238.9px; height: 445.90000000000003px;" /></a>
</section>
<section id="custom-rewards">
<h2>Custom rewards<a class="headerlink" href="#custom-rewards" title="Link to this heading">ÔÉÅ</a></h2>
<p>Defining custom reward functions is straightforward. For instance, a reward signal that always returns -1 can be implemented as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sinergym.utils.rewards</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseReward</span>

<span class="k">class</span><span class="w"> </span><span class="nc">CustomReward</span><span class="p">(</span><span class="n">BaseReward</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Naive reward function.&quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CustomReward</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="p">{}</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;Eplus-discrete-stochastic-mixed-v1&#39;</span><span class="p">,</span> <span class="n">reward</span><span class="o">=</span><span class="n">CustomReward</span><span class="p">)</span>
</pre></div>
</div>
<p>For advanced reward functions, we recommend inheriting from the main class, <code class="docutils literal notranslate"><span class="pre">LinearReward</span></code>, and overriding the default methods.</p>
<p>Pre-defined reward functions simplify observation processing to extract consumption and comfort violation data, from which  penalty values are calculated. Weighted reward terms are then computed from these penalties and subsequently added.</p>
<a class="reference internal image-reference" href="../_images/reward_structure.png"><img alt="Reward steps structure" class="align-center" src="../_images/reward_structure.png" style="width: 792.8800000000001px; height: 539.24px;" /></a>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="output.html" class="btn btn-neutral float-left" title="Sinergym output" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="controllers.html" class="btn btn-neutral float-right" title="Controllers" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, J. Jim√©nez, J. G√≥mez, M. Molina, A. Manjavacas, A. Campoy.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        <span class="fa fa-book"> Other Versions</span>
        v: v3.7.0
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl>
            <dt>Tags</dt>
            <dd><a href="../../v1.4.0/pages/rewards.html">v1.4.0</a></dd>
            <dd><a href="../../v1.6.0/pages/rewards.html">v1.6.0</a></dd>
            <dd><a href="../../v1.7.0/pages/rewards.html">v1.7.0</a></dd>
            <dd><a href="../../v2.0.0/pages/rewards.html">v2.0.0</a></dd>
            <dd><a href="../../v2.1.0/pages/rewards.html">v2.1.0</a></dd>
            <dd><a href="../../v2.2.0/pages/rewards.html">v2.2.0</a></dd>
            <dd><a href="../../v2.3.0/pages/rewards.html">v2.3.0</a></dd>
            <dd><a href="../../v2.5.0/pages/rewards.html">v2.5.0</a></dd>
            <dd><a href="../../v3.1.0/pages/rewards.html">v3.1.0</a></dd>
            <dd><a href="../../v3.2.0/pages/rewards.html">v3.2.0</a></dd>
            <dd><a href="../../v3.3.0/pages/rewards.html">v3.3.0</a></dd>
            <dd><a href="../../v3.4.0/pages/rewards.html">v3.4.0</a></dd>
            <dd><a href="../../v3.5.0/pages/rewards.html">v3.5.0</a></dd>
            <dd><a href="../../v3.6.0/pages/rewards.html">v3.6.0</a></dd>
            <dd><a href="rewards.html">v3.7.0</a></dd>
            <dd><a href="../../v3.8.0/pages/rewards.html">v3.8.0</a></dd>
            <dd><a href="../../v3.9.0/pages/rewards.html">v3.9.0</a></dd>
        </dl>
        <dl>
            <dt>Branches</dt>
            <dd><a href="../../main/pages/rewards.html">main</a></dd>
        </dl>
    </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>  

<style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search,
    .wy-nav-top {
        background: #a5beba;
    }

    /* Sidebar */
    .wy-nav-side {
        background: #2b3435;
    }
</style>


</body>
</html>