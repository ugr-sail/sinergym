{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# DRL usage example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook example, we've used Stable Baselines 3 to train and load an agent. However, Sinergym is entirely agnostic to any DRL algorithm (though it does have custom callbacks specifically for SB3) and can be used with any DRL library that interfaces with Gymnasium."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We'll be using the `train_agent.py` script located in the repository root. This script leverages all the capabilities of Sinergym for working with deep reinforcement learning algorithms and sets parameters for everything, allowing us to easily define training options via a JSON file when executing the script.\n",
    "\n",
    "For more details on how to run `train_agent.py`, please refer to [Train a model](https://ugr-sail.github.io/sinergym/compilation/main/pages/deep-reinforcement-learning.html#model-training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import wandb\n",
    "from stable_baselines3 import *\n",
    "from stable_baselines3.common.callbacks import CallbackList\n",
    "from stable_baselines3.common.logger import HumanOutputFormat\n",
    "from stable_baselines3.common.logger import Logger as SB3Logger\n",
    "\n",
    "import sinergym\n",
    "from sinergym.utils.callbacks import *\n",
    "from sinergym.utils.constants import *\n",
    "from sinergym.utils.logger import WandBOutputFormat\n",
    "from sinergym.utils.rewards import *\n",
    "from sinergym.utils.wrappers import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First, let's set some variables for the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Environment ID\n",
    "environment = \"Eplus-5zone-mixed-continuous-stochastic-v1\"\n",
    "# Training episodes\n",
    "episodes = 5\n",
    "#Name of the experiment\n",
    "experiment_date = datetime.today().strftime('%Y-%m-%d_%H:%M')\n",
    "experiment_name = 'SB3_PPO-' + environment + \\\n",
    "    '-episodes-' + str(episodes)\n",
    "experiment_name += '_' + experiment_date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, we're ready to create the Gym environment. We'll use the previously defined environment name, but remember that you can [change the default environment configuration](https://ugr-sail.github.io/sinergym/compilation/main/pages/notebooks/change_environment.html#Changing-an-environment-registered-in-Sinergym). We'll also create an eval_env for evaluation episodes. If desired, we can replace the env name with the experiment name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-20_11:17]\u001b[0m\n",
      "#==============================================================================================#\n",
      "\u001b[38;20m[MODELING] (INFO) : Experiment working directory created [/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-20_11:17-res1]\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Model Config is correct.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Variable available names\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Meter available names\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : runperiod established: {'start_day': 1, 'start_month': 1, 'start_year': 1991, 'end_day': 31, 'end_month': 12, 'end_year': 1991, 'start_weekday': 0, 'n_steps_per_hour': 4}\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : timesteps per episode: 35041\u001b[0m\n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-20_11:17 created successfully.\u001b[0m\n",
      "#==============================================================================================#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-20_11:17_EVALUATION]\u001b[0m\n",
      "#==============================================================================================#\n",
      "\u001b[38;20m[MODELING] (INFO) : Experiment working directory created [/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-20_11:17_EVALUATION-res1]\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Model Config is correct.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Variable available names\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Meter available names\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : runperiod established: {'start_day': 1, 'start_month': 1, 'start_year': 1991, 'end_day': 31, 'end_month': 12, 'end_year': 1991, 'start_weekday': 0, 'n_steps_per_hour': 4}\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : timesteps per episode: 35041\u001b[0m\n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-20_11:17_EVALUATION created successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment, env_name=experiment_name)\n",
    "eval_env = gym.make(environment, env_name=experiment_name+'_EVALUATION')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can also add wrappers to the environment. We'll use an action and observation normalization wrapper and *Sinergym* logger. Normalization is highly recommended for DRL algorithms with continuous action space, and the logger is used to monitor and log environment interactions and save the data, and then dump it into CSV files and/or wandb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Wrapper initialized.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeAction] (INFO) : New normalized action Space: Box(-1.0, 1.0, (2,), float32)\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeAction] (INFO) : Wrapper initialized\u001b[0m\n",
      "\u001b[38;20m[WRAPPER LoggerWrapper] (INFO) : Wrapper initialized.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER CSVLogger] (INFO) : Wrapper initialized.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Wrapper initialized.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeAction] (INFO) : New normalized action Space: Box(-1.0, 1.0, (2,), float32)\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeAction] (INFO) : Wrapper initialized\u001b[0m\n",
      "\u001b[38;20m[WRAPPER LoggerWrapper] (INFO) : Wrapper initialized.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER CSVLogger] (INFO) : Wrapper initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = NormalizeObservation(env)\n",
    "env = NormalizeAction(env)\n",
    "env = LoggerWrapper(env)\n",
    "env = CSVLogger(env)\n",
    "# Discomment the following line to log to WandB (remmeber to set the API key in a environment variable)\n",
    "# env = WandBLogger(env, \n",
    "#                  entity='sinergym', \n",
    "#                  project_name='sail_ugr',\n",
    "#                  run_name=experiment_name,\n",
    "#                  group='Train_example',\n",
    "#                  tags=['DRL', 'PPO', '5zone', 'continuous', 'stochastic', 'v1'],\n",
    "#                  save_code = True,\n",
    "#                  dump_frequency = 1000,\n",
    "#                  artifact_save = True)\n",
    "eval_env = NormalizeObservation(eval_env)\n",
    "eval_env = NormalizeAction(eval_env)\n",
    "eval_env = LoggerWrapper(eval_env)\n",
    "eval_env = CSVLogger(eval_env)\n",
    "# Evaluation env is not required to wrapp with WandBLogger since the calculations are added in the same WandB session than the training env,\n",
    "# using the sinergym LoggerEvalCallback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "At this point, the environment is set up and ready to use. We'll create our learning model (Stable Baselines 3 PPO), but any other algorithm can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# In this case, all the hyperparameters are the default ones\n",
    "model = PPO('MlpPolicy', env, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `WandBLogger` is active, we can log all hyperparameters there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register hyperparameters in wandb if it is wrapped\n",
    "if is_wrapped(env, WandBLogger):\n",
    "    experiment_params = {\n",
    "        'sinergym-version': sinergym.__version__,\n",
    "        'python-version': sys.version\n",
    "    }\n",
    "    # experiment_params.update(conf)\n",
    "    env.get_wrapper_attr('wandb_run').config.update(experiment_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Evaluation will run the current model for a set number of episodes to determine if it's the best current version of the model at that training stage. The generated output will also be stored depending used logger wrappers. We'll use the LoggerEval callback to print and save the best evaluated model during training, saving in local CSV files and WandB platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "\n",
    "# Set up Evaluation logging and saving best model\n",
    "eval_callback = LoggerEvalCallback(\n",
    "            eval_env=eval_env,\n",
    "            train_env=env,\n",
    "            n_eval_episodes=1,\n",
    "            eval_freq_episodes=2,\n",
    "            deterministic=True)\n",
    "callbacks.append(eval_callback)\n",
    "callback = CallbackList(callbacks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add the SB3 logging values in the same WandB session too, we need to create a compatible wandb output format (which calls the *wandb* log method in the learning algorithm process). *Sinergym* has implemented one called `WandBOutputFormat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb logger and setting in SB3\n",
    "if is_wrapped(env, WandBLogger):\n",
    "    # wandb logger and setting in SB3\n",
    "    logger = SB3Logger(\n",
    "        folder=None,\n",
    "        output_formats=[\n",
    "            HumanOutputFormat(\n",
    "                sys.stdout,\n",
    "                max_length=120),\n",
    "            WandBOutputFormat()])\n",
    "    model.set_logger(logger)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This is the total number of time steps for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "timesteps = episodes * (env.get_wrapper_attr('timestep_per_episode') - 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, it's time to train the model with the previously defined callback. This may take a few minutes, depending on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.learn(\n",
    "    total_timesteps=timesteps,\n",
    "    callback=callback,\n",
    "    log_interval=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, we save the current model (the model version when training has finished). We will save the mean and var normalization calibration in order to use it in model evaluation, although these values can be consulted later in a txt saved in Sinergym training output. Visit NormalizeObservation wrapper documentation for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save(env.get_wrapper_attr('workspace_path') + '/model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And as always, remember to close the environment. If WandB is active with logger, this close will save artifacts with whole experiment output and evaluation executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m[WRAPPER CSVLogger] (INFO) : Environment closed, data updated in monitor and progress.csv.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40]\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Saving normalization calibration data... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |***************************************************************************************************| 99%\n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All experiment results are stored locally, but you can also view the execution in *wandb*:\n",
    "\n",
    "- When you check your projects, you'll see the execution allocated:\n",
    "\n",
    "![wandb_projects1](https://github.com/ugr-sail/sinergym/blob/main/images/wandb_projects1.png?raw=true)\n",
    "\n",
    "- The training experiment's tracked hyperparameters:\n",
    "\n",
    "![wandb_training_hyperparameters](https://github.com/ugr-sail/sinergym/blob/main/images/wandb_training_hyperparameters.png?raw=true)\n",
    "\n",
    "- Registered artifacts (if evaluation is enabled, the best model is also registered):\n",
    "\n",
    "![wandb_training_artifact](https://github.com/ugr-sail/sinergym/blob/main/images/wandb_training_artifact.png?raw=true)\n",
    "\n",
    "- Real-time visualization of metrics:\n",
    "\n",
    "![wandb_training_charts](https://github.com/ugr-sail/sinergym/blob/main/images/wandb_training_charts.png?raw=true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the `load_agent.py` script located in the repository root. This script leverages all the capabilities of Sinergym for working with loaded deep reinforcement learning models and sets parameters for everything, allowing us to easily define load options via a JSON file when executing the script.\n",
    "\n",
    "For more details on how to run `load_agent.py`, please refer to [Load a trained model](https://ugr-sail.github.io/sinergym/compilation/main/pages/deep-reinforcement-learning.html#model-loading)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll define the Sinergym environment ID where we want to test the loaded agent and the name of the evaluation experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment ID\n",
    "environment = \"Eplus-5zone-mixed-continuous-stochastic-v1\"\n",
    "# Episodes\n",
    "episodes=5\n",
    "# Evaluation name\n",
    "evaluation_date = datetime.today().strftime('%Y-%m-%d_%H:%M')\n",
    "evaluation_name = 'SB3_PPO-EVAL-' + environment + \\\n",
    "    '-episodes-' + str(episodes)\n",
    "evaluation_name += '_' + evaluation_date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create the Gym environment, but it's **important to wrap the environment with the same wrappers, whose action and observation observation spaces were modified, used during training**. We can use the evaluation experiment name to rename the environment.\n",
    "\n",
    "**Note**: If you are loading a pre-trained model and using the observation space normalization wrapper, you should use the means and variations calibrated during the training process for a fair evaluation. The next code specifies this aspect, those mean and var values are written in Sinergym training output as txt file automatically if you want to consult it later. You can use the list/numpy array values or set the txt path directly in the field constructor. It is also important to deactivate calibration update during evaluations. Check the documentation on the wrapper for more information. This task is done automatically in `LoggerEvalCallback`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment... [SB3_PPO-EVAL-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:48]\u001b[0m\n",
      "#==============================================================================================#\n",
      "\u001b[38;20m[MODELING] (INFO) : Experiment working directory created [/workspaces/sinergym/examples/Eplus-env-SB3_PPO-EVAL-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:48-res1]\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Model Config is correct.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Variable available names\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Meter available names\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : runperiod established: {'start_day': 1, 'start_month': 1, 'start_year': 1991, 'end_day': 31, 'end_month': 12, 'end_year': 1991, 'start_weekday': 0, 'n_steps_per_hour': 4}\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : timesteps per episode: 35041\u001b[0m\n",
      "\u001b[38;20m[REWARD] (INFO) : Reward function initialized.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment SB3_PPO-EVAL-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:48 created successfully.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Wrapper initialized.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeAction] (INFO) : New normalized action Space: Box(-1.0, 1.0, (2,), float32)\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeAction] (INFO) : Wrapper initialized\u001b[0m\n",
      "\u001b[38;20m[WRAPPER LoggerWrapper] (INFO) : Wrapper initialized.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER CSVLogger] (INFO) : Wrapper initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "evaluation_env = gym.make(environment, env_name=evaluation_name)\n",
    "evaluation_env = NormalizeObservation(evaluation_env, mean = env.get_wrapper_attr(\"mean\"), var = env.get_wrapper_attr(\"var\"), automatic_update=False)\n",
    "evaluation_env = NormalizeAction(evaluation_env)\n",
    "evaluation_env = LoggerWrapper(evaluation_env)\n",
    "evaluation_env = CSVLogger(evaluation_env)\n",
    "# If you want to log the evaluation interactions to WandB, use WandBLogger too"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load the Stable Baselines 3 PPO model from our local computer, but we could also use a remote model stored in *wandb* from another training experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wandb artifact path (to load model)\n",
    "if is_wrapped(evaluation_env, WandBLogger):\n",
    "    wandb_run = evaluation_env.get_wrapper_attr('wandb_run')\n",
    "else:\n",
    "    wandb_run = wandb.init(entity = 'sail_ugr')\n",
    "    \n",
    "load_artifact_entity = 'sail_ugr'\n",
    "load_artifact_project = 'sinergym'\n",
    "load_artifact_name = experiment_name\n",
    "load_artifact_tag = 'latest'\n",
    "load_artifact_model_path = 'Sinergym_output/evaluation/best_model.zip'\n",
    "wandb_path = load_artifact_entity + '/' + load_artifact_project + \\\n",
    "    '/' + load_artifact_name + ':' + load_artifact_tag\n",
    "# Download artifact\n",
    "artifact = wandb_run.use_artifact(wandb_path)\n",
    "artifact.get_path(load_artifact_model_path).download('.')\n",
    "# Set model path to local wandb file downloaded\n",
    "model_path = './' + load_artifact_model_path\n",
    "model = PPO.load(model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the *wandb* model we want to load can come from an artifact of a different entity or project than the one we're using to register the evaluation of the loaded model, as long as it's accessible.\n",
    "The next step is to use the model to predict actions and interact with the environment to collect data for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40] [Episode 7]\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode directory created [/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run7]\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Weather file USA_NY_New.York-J.F.Kennedy.Intl.AP.744860_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Adapting weather to building model. [USA_NY_New.York-J.F.Kennedy.Intl.AP.744860_TMY3.epw]\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path... [/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run7/output]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/opyplus/weather_data/weather_data.py:485: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m[SIMULATOR] (INFO) : Running EnergyPlus with args: ['-w', '/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run7/USA_NY_New.York-J.F.Kennedy.Intl.AP.744860_TMY3_Random_1.0_0.0_0.001.epw', '-d', '/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run7/output', '/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run7/5ZoneAutoDXVAV.epJSON']\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 7 started.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Saving normalization calibration data... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40]\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Saving normalization calibration data... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40]\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "1 -1.6446008069134792\n",
      "2 -2535.9359450953466-----------------------------------------------------------------------------------------| 9%\n",
      "3 -4823.4260633241665******-----------------------------------------------------------------------------------| 16%\n",
      "4 -7364.053050786045****************--------------------------------------------------------------------------| 25%\n",
      "5 -10181.732275386925***********************------------------------------------------------------------------| 33%\n",
      "6 -13215.13622884691********************************----------------------------------------------------------| 41%\n",
      "7 -14626.421671023001****************************************-------------------------------------------------| 50%\n",
      "8 -16211.2274234831*************************************************------------------------------------------| 58%\n",
      "9 -17762.154093987843********************************************************---------------------------------| 66%\n",
      "10 -19114.586326032266****************************************************************------------------------| 75%\n",
      "11 -22079.542120929047************************************************************************----------------| 83%\n",
      "12 -24505.240849155747********************************************************************************--------| 91%\n",
      "Progress: |***************************************************************************************************| 99%\n",
      "Episode  0 Mean reward:  -0.7698908037188604 Cumulative reward:  -26977.743653112586\n",
      "\u001b[38;20m[WRAPPER CSVLogger] (INFO) : End of episode detected, data updated in monitor and progress.csv.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER CSVLogger] (INFO) : End of episode detected, data updated in monitor and progress.csv.\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40] [Episode 8]\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode directory created [/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run8]\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Weather file USA_NY_New.York-J.F.Kennedy.Intl.AP.744860_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Adapting weather to building model. [USA_NY_New.York-J.F.Kennedy.Intl.AP.744860_TMY3.epw]\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path... [/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run8/output]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/opyplus/weather_data/weather_data.py:485: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m[SIMULATOR] (INFO) : Running EnergyPlus with args: ['-w', '/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run8/USA_NY_New.York-J.F.Kennedy.Intl.AP.744860_TMY3_Random_1.0_0.0_0.001.epw', '-d', '/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run8/output', '/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run8/5ZoneAutoDXVAV.epJSON']\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 8 started.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Saving normalization calibration data... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40]\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Saving normalization calibration data... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40]\u001b[0m\n",
      "1 -1.7995207922238332\n",
      "2 -2525.907934259986------------------------------------------------------------------------------------------| 9%\n",
      "3 -4833.829075719896*******-----------------------------------------------------------------------------------| 16%\n",
      "4 -7383.058739944303****************--------------------------------------------------------------------------| 25%\n",
      "5 -10135.751693178638***********************------------------------------------------------------------------| 33%\n",
      "6 -13203.476618527327*******************************----------------------------------------------------------| 41%\n",
      "7 -14631.222012238866****************************************-------------------------------------------------| 50%\n",
      "8 -16232.522719327082***********************************************------------------------------------------| 58%\n",
      "9 -17753.958387954357********************************************************---------------------------------| 66%\n",
      "10 -19146.864311365585****************************************************************------------------------| 75%\n",
      "11 -22069.136934518898************************************************************************----------------| 83%\n",
      "12 -24526.976100128184********************************************************************************--------| 91%\n",
      "Progress: |***************************************************************************************************| 99%\n",
      "Episode  1 Mean reward:  -0.7699928837281512 Cumulative reward:  -26980.550645834417\n",
      "\u001b[38;20m[WRAPPER CSVLogger] (INFO) : End of episode detected, data updated in monitor and progress.csv.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER CSVLogger] (INFO) : End of episode detected, data updated in monitor and progress.csv.\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40] [Episode 9]\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode directory created [/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run9]\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Weather file USA_NY_New.York-J.F.Kennedy.Intl.AP.744860_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Adapting weather to building model. [USA_NY_New.York-J.F.Kennedy.Intl.AP.744860_TMY3.epw]\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path... [/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run9/output]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/opyplus/weather_data/weather_data.py:485: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m[SIMULATOR] (INFO) : Running EnergyPlus with args: ['-w', '/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run9/USA_NY_New.York-J.F.Kennedy.Intl.AP.744860_TMY3_Random_1.0_0.0_0.001.epw', '-d', '/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run9/output', '/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run9/5ZoneAutoDXVAV.epJSON']\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 9 started.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Saving normalization calibration data... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40]\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Saving normalization calibration data... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40]\u001b[0m\n",
      "1 -1.7933100220830442\n",
      "2 -2538.445643551368------------------------------------------------------------------------------------------| 9%\n",
      "3 -4836.026266378525*******-----------------------------------------------------------------------------------| 16%\n",
      "4 -7398.170606903661****************--------------------------------------------------------------------------| 25%\n",
      "5 -10215.490911458011***********************------------------------------------------------------------------| 33%\n",
      "6 -13270.859682680994*******************************----------------------------------------------------------| 41%\n",
      "7 -14673.470077032065****************************************-------------------------------------------------| 50%\n",
      "8 -16277.010656826511***********************************************------------------------------------------| 58%\n",
      "9 -17859.96995901266*********************************************************---------------------------------| 66%\n",
      "10 -19229.724716059914****************************************************************------------------------| 75%\n",
      "11 -22190.489836264052************************************************************************----------------| 83%\n",
      "12 -24654.54683199728*********************************************************************************--------| 91%\n",
      "Progress: |***************************************************************************************************| 99%\n",
      "Episode  2 Mean reward:  -0.7740173991820579 Cumulative reward:  -27121.569667339314\n",
      "\u001b[38;20m[WRAPPER CSVLogger] (INFO) : End of episode detected, data updated in monitor and progress.csv.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER CSVLogger] (INFO) : End of episode detected, data updated in monitor and progress.csv.\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40] [Episode 10]\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode directory created [/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run10]\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Weather file USA_NY_New.York-J.F.Kennedy.Intl.AP.744860_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Adapting weather to building model. [USA_NY_New.York-J.F.Kennedy.Intl.AP.744860_TMY3.epw]\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path... [/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run10/output]\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : Running EnergyPlus with args: ['-w', '/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run10/USA_NY_New.York-J.F.Kennedy.Intl.AP.744860_TMY3_Random_1.0_0.0_0.001.epw', '-d', '/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run10/output', '/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run10/5ZoneAutoDXVAV.epJSON']\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 10 started.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/opyplus/weather_data/weather_data.py:485: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Saving normalization calibration data... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40]\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Saving normalization calibration data... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40]\u001b[0m\n",
      "1 -1.7162450174060817\n",
      "2 -2515.235832234475------------------------------------------------------------------------------------------| 9%\n",
      "3 -4835.124638771841*******-----------------------------------------------------------------------------------| 16%\n",
      "4 -7407.433874239768****************--------------------------------------------------------------------------| 25%\n",
      "5 -10197.88881457567************************------------------------------------------------------------------| 33%\n",
      "6 -13209.917010355572*******************************----------------------------------------------------------| 41%\n",
      "7 -14581.792369056018****************************************-------------------------------------------------| 50%\n",
      "8 -16196.423742594645***********************************************------------------------------------------| 58%\n",
      "9 -17691.01897293819*********************************************************---------------------------------| 66%\n",
      "10 -19067.20513247273*****************************************************************------------------------| 75%\n",
      "11 -22016.093939425933************************************************************************----------------| 83%\n",
      "12 -24454.153731838967********************************************************************************--------| 91%\n",
      "Progress: |***************************************************************************************************| 99%\n",
      "Episode  3 Mean reward:  -0.7670151345390938 Cumulative reward:  -26876.210314249845\n",
      "\u001b[38;20m[WRAPPER CSVLogger] (INFO) : End of episode detected, data updated in monitor and progress.csv.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER CSVLogger] (INFO) : End of episode detected, data updated in monitor and progress.csv.\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40] [Episode 11]\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode directory created [/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run11]\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Weather file USA_NY_New.York-J.F.Kennedy.Intl.AP.744860_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Adapting weather to building model. [USA_NY_New.York-J.F.Kennedy.Intl.AP.744860_TMY3.epw]\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path... [/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run11/output]\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : Running EnergyPlus with args: ['-w', '/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run11/USA_NY_New.York-J.F.Kennedy.Intl.AP.744860_TMY3_Random_1.0_0.0_0.001.epw', '-d', '/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run11/output', '/workspaces/sinergym/examples/Eplus-env-SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40-res1/Eplus-env-sub_run11/5ZoneAutoDXVAV.epJSON']\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 11 started.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/opyplus/weather_data/weather_data.py:485: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Saving normalization calibration data... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40]\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Saving normalization calibration data... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40]\u001b[0m\n",
      "1 -1.9855085492179452\n",
      "2 -2525.9765795852795-----------------------------------------------------------------------------------------| 9%\n",
      "3 -4836.447992908011*******-----------------------------------------------------------------------------------| 16%\n",
      "4 -7415.106488666047****************--------------------------------------------------------------------------| 25%\n",
      "5 -10199.115705433655***********************------------------------------------------------------------------| 33%\n",
      "6 -13226.748838894438*******************************----------------------------------------------------------| 41%\n",
      "7 -14570.022002702428****************************************-------------------------------------------------| 50%\n",
      "8 -16163.73052129073************************************************------------------------------------------| 58%\n",
      "9 -17710.726350820067********************************************************---------------------------------| 66%\n",
      "10 -19090.64622045218*****************************************************************------------------------| 75%\n",
      "11 -22118.184102555933************************************************************************----------------| 83%\n",
      "12 -24523.10955600609*********************************************************************************--------| 91%\n",
      "Progress: |***************************************************************************************************| 99%\n",
      "Episode  4 Mean reward:  -0.770449260651564 Cumulative reward:  -26996.542093230804\n",
      "\u001b[38;20m[WRAPPER CSVLogger] (INFO) : Environment closed, data updated in monitor and progress.csv.\u001b[0m\n",
      "\u001b[38;20m[WRAPPER CSVLogger] (INFO) : Environment closed, data updated in monitor and progress.csv.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40]\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Saving normalization calibration data... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40]\u001b[0m\n",
      "\u001b[38;20m[WRAPPER NormalizeObservation] (INFO) : Saving normalization calibration data... [SB3_PPO-Eplus-5zone-mixed-continuous-stochastic-v1-episodes-5_2024-08-07_15:40]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i in range(episodes):\n",
    "    obs, info = evaluation_env.reset()\n",
    "    rewards = []\n",
    "    truncated = terminated = False\n",
    "    current_month = 0\n",
    "    while not (terminated or truncated):\n",
    "        a, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = evaluation_env.step(a)\n",
    "        rewards.append(reward)\n",
    "        if info['month'] != current_month:\n",
    "            current_month = info['month']\n",
    "            print(info['month'], sum(rewards))\n",
    "    print(\n",
    "        'Episode ',\n",
    "        i,\n",
    "        'Mean reward: ',\n",
    "        np.mean(rewards),\n",
    "        'Cumulative reward: ',\n",
    "        sum(rewards))\n",
    "evaluation_env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from the loaded model are stored locally, but you can also view the execution in *wandb* if WandBLogger were used:\n",
    "\n",
    "- When you check the wandb project list, you'll see that the sinergym_evaluations project has a new run:\n",
    "\n",
    "![wandb_project2](https://github.com/ugr-sail/sinergym/blob/main/images/wandb_project2.png?raw=true)\n",
    "\n",
    "- The evaluation experiment's tracked hyperparameters, and the previous training artifact used to load the model:\n",
    "\n",
    "![wandb_evaluating_hyperparameters](https://github.com/ugr-sail/sinergym/blob/main/images/wandb_evaluating_hyperparameters.png?raw=true)\n",
    "\n",
    "- The registered artifact with Sinergym Output (and CSV files generated with the Logger Wrapper):\n",
    "\n",
    "![wandb_evaluating_artifact](https://github.com/ugr-sail/sinergym/blob/main/images/wandb_evaluating_artifact.png?raw=true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
