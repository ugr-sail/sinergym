program: launch_agent.py
method: grid
parameters:
# ---------------------------------- BASICS ---------------------------------- #
  environment:
    value: 'Eplus-5zone-hot-discrete-stochastic-v1'
  episodes:
    value: 5
  log_interval:
    value: 10
# --------------------------------- ALGORITHM -------------------------------- #
  algorithm:
    value: DQN
  # Algorithm parameters group
  algorithm_parameters:
    parameters:
      policy:
        value: 'MlpPolicy'
      learning_rate:
        values: 
          - 1.0e-4
      buffer_size:
        value: 1_000_000
      learning_starts:
        value: 50000
      batch_size:
        value: 32
      tau:
        value: 1.0
      gamma:
        value: 0.99
      train_freq:
        value: 4
      gradient_steps:
        value: 1
      replay_buffer_class:
        value: null
      replay_buffer_kwargs:
        value: null
      optimize_memory_usage:
        value: False
      target_update_interval:
        value: 10000
      exploration_fraction:
        value: 0.1
      exploration_initial_eps:
        value: 1.0
      exploration_final_eps:
        value: 0.05
      max_grad_norm:
        value: 10
      stats_window_size:
        value: 100
      tensorboard_log:
        value: null
      policy_kwargs:
        value: null
      verbose:
        value: 1
      seed:
        value: null
      device:
        value: 'auto'
      _init_setup_model:
        value: True
# -------------------------------- EVALUATION -------------------------------- #
  evaluation: # Set null when you don't want evaluation
    parameters:
      eval_freq:
        value: 2
      eval_length:
        value: 1
# -------------------------------- ENVIRONMENT ------------------------------- #
  environment_parameters:
    parameters:
      seed:
        value: null
      weather_variability:
        values:
        - {
          Dry Bulb Temperature: [1.0,0.0,24.0]
        }
      reward:
        value: LinearReward
      # ... other environment parameters

# --------------------------------- WRAPPERS --------------------------------- #
  wrappers:
    values: 
      - [
          ['NormalizeObservation', {}],
          ['LoggerWrapper', {}],
          ['CSVLogger',{}],
          ['WandBLogger', {'save_code': True,
                          'dump_frequency': 1000,
                          'artifact_save': True,
                          'artifact_type': 'output',
                          'excluded_info_keys': ['reward',
                                                  'action',
                                                  'timestep',
                                                  'month',
                                                  'day',
                                                  'hour',
                                                  'time_elapsed(hours)',
                                                  'reward_weight',
                                                  'is_raining'],
                          'excluded_episode_summary_keys':['terminated',
                                                            'truncated']
                          }
          ],
      ]

# --------------------------- INITIAL STATE (MODEL) -------------------------- #
  # Model from scratch:
  model:
    value: null

  # Local Path:
  # model:
  #   value: 
  #     local_path: </path/to/model>
  #     # load model normalization if needed
  #     normalization:
  #       mean: Sinergym_output/evaluation/mean.txt
  #       var: Sinergym_output/evaluation/var.txt

  # Google Bucket Path:
  # model:
  #   value:
  #     bucket_path: gs://<path_to_model_google_bucket>
  #     # load model normalization if needed
  #     normalization:
  #       mean: <<path_to_model_google_bucket_mean.txt>
  #       var: <<path_to_model_google_bucket_var.txt>

  # WANDB model path:
  # model:
  #   value:
  #     project: test-project
  #     entity: sail_ugr
  #     artifact_name: PPO-Eplus-5zone-hot-continuous-stochastic-v1-episodes-5-id-PPOExperimentExample_2025-02-02_18-31_9jau51uy
  #     artifact_type: output
  #     artifact_tag: v0
  #     artifact_path: Sinergym_output/evaluation/
  #     model_path: Sinergym_output/evaluation/best_model.zip
  #     # load model normalization if needed
  #     normalization:
  #       mean: Sinergym_output/evaluation/mean.txt
  #       var: Sinergym_output/evaluation/var.txt

# -------------------------- GOOGLE CLOUD (OPTIONAL) ------------------------- #
# cloud: 
#   remote_store: null # remote bucket name
#   auto_delete: null # Delete remote instance when finish experiment
  # auto_delete:
  #   group_name: group-example
  
      