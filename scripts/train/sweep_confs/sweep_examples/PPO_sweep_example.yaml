program: launch_agent.py
method: grid
parameters:
# ---------------------------------- BASICS ---------------------------------- #
  environment:
    value: 'Eplus-5zone-hot-continuous-stochastic-v1'
  episodes:
    value: 5
  log_interval:
    value: 10
# --------------------------------- ALGORITHM -------------------------------- #
  algorithm:
    value: PPO
  # Algorithm parameters group
  algorithm_parameters:
    parameters:
      policy:
        value: 'MlpPolicy'
      learning_rate:
        values: 
          - 3.0e-4
          - 1.0e-3
      n_steps:
        value: 2048
      batch_size:
        values:
          - 256
          - 512
      n_epochs:
        value: 10
      gamma:
        value: 0.99
      gae_lambda:
        value: 0.95
      clip_range:
        value: 0.2
      clip_range_vf:
        value: null
      normalize_advantage:
        value: True
      ent_coef:
        values: 
          - 0.0
      vf_coef:
        value: 0.5
      max_grad_norm:
        value: 0.5
      use_sde:
        value: False
      sde_sample_freq:
        value: -1
      rollout_buffer_class:
        value: null
      rollout_buffer_kwargs:
        value: null
      target_kl:
        value: null
      stats_window_size:
        value: 100
      tensorboard_log:
        value: null
      policy_kwargs:
        value: null
      verbose:
        value: 1
      seed:
        value: null
      device:
        value: 'auto'
      _init_setup_model:
        value: True
# -------------------------------- EVALUATION -------------------------------- #
  evaluation: # Set null when you don't want evaluation
    parameters:
      eval_freq:
        value: 2
      eval_length:
        value: 1
# -------------------------------- ENVIRONMENT ------------------------------- #
  # Yaml file with environment configuration (Optional)
  env_yaml_config:
    value: null
  
  # In order to overwrite some parameters of the environment, you can use the following
  environment_parameters:
    parameters:
      seed:
        value: null
      weather_variability:
        values:
        - {
          Dry Bulb Temperature: [1.0,0.0,24.0]
        }
      reward:
        value: sinergym.utils.rewards:LinearReward
      # ... other environment parameters

# --------------------------------- WRAPPERS --------------------------------- #
  # Yaml file with wrappers configuration for environment (Optional)
  wrappers_yaml_config:
    value: null
  
  # This definition is ignored if wrappers_yaml_config is defined
  wrappers:
    value: 
      - sinergym.utils.wrappers:NormalizeObservation: {}
      - sinergym.utils.wrappers:NormalizeAction: {}
      - sinergym.utils.wrappers:LoggerWrapper: {}
      - sinergym.utils.wrappers:CSVLogger: {}
      - sinergym.utils.wrappers:WandBLogger: 
          save_code: True
          dump_frequency: 1000
          artifact_save: True
          artifact_type: output
          excluded_info_keys: 
            - reward
            - action
            - timestep
            - month
            - day
            - hour
            - time_elapsed(hours)
            - reward_weight
            - is_raining
          excluded_episode_summary_keys:
            - terminated
            - truncated

# --------------------------- INITIAL STATE (MODEL) -------------------------- #
  # Model from scratch:
  model:
    value: null

  # Local Path:
  # model:
  #   value: 
  #     local_path: </path/to/model>
  #     # load model normalization if needed
  #     normalization:
  #       mean: Sinergym_output/evaluation/mean.txt
  #       var: Sinergym_output/evaluation/var.txt

  # Google Bucket Path:
  # model:
  #   value:
  #     bucket_path: gs://<path_to_model_google_bucket>
  #     # load model normalization if needed
  #     normalization:
  #       mean: <<path_to_model_google_bucket_mean.txt>
  #       var: <<path_to_model_google_bucket_var.txt>

  # WANDB model path:
  # model:
  #   value:
  #     project: test-project
  #     entity: sail_ugr
  #     artifact_name: PPO-Eplus-5zone-hot-continuous-stochastic-v1-episodes-5-id-PPOExperimentExample_2025-02-02_18-31_9jau51uy
  #     artifact_type: output
  #     artifact_tag: v0
  #     artifact_path: Sinergym_output/evaluation/
  #     model_path: Sinergym_output/evaluation/best_model.zip
  #     # load model normalization if needed
  #     normalization:
  #       mean: Sinergym_output/evaluation/mean.txt
  #       var: Sinergym_output/evaluation/var.txt

# -------------------------- GOOGLE CLOUD (OPTIONAL) ------------------------- #
# cloud: 
#   remote_store: null # remote bucket name
  
      