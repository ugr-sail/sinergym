# ---------------------------------- BASICS ---------------------------------- #
id: PPO_training
environment: Eplus-5zone-hot-continuous-stochastic-v1
episodes: 5

# ------------------------------- SB3 ALGORITHM ------------------------------ #
algorithm:
  name: PPO
  log_interval: 1
  parameters:
    policy: MlpPolicy
    learning_rate: 0.0003
    n_steps: 2048
    batch_size: 64
    n_epochs: 10
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    clip_range_vf: null
    normalize_advantage: true
    ent_coef: 0
    vf_coef: 0.5
    max_grad_norm: 0.5
    use_sde: false
    sde_sample_freq: -1
    rollout_buffer_class: null
    rollout_buffer_kwargs: null
    target_kl: null
    stats_window_size: 100
    tensorboard_log: null
    policy_kwargs: null
    verbose: 1
    seed: null
    device: auto
    _init_setup_model: true

# -------------------------------- EVALUATION -------------------------------- #
evaluation:
  eval_freq: 2
  eval_length: 1

# -------------------------------- ENVIRONMENT ------------------------------- #
# Yaml file with environment configuration (Optional)
env_yaml_config: null
# In order to overwrite some parameters of the environment, you can use the following
env_params:
  seed: null
  reward: sinergym.utils.rewards:LinearReward
# ... other environment parameters

# ---------------------------------- WRAPPER --------------------------------- #
# Yaml file with wrappers configuration (Optional)
wrappers_yaml_config: null
# This definition is ignored if wrappers_yaml_config is defined
wrappers:
  sinergym.utils.wrappers:NormalizeAction: {}
  sinergym.utils.wrappers:NormalizeObservation: {}
  sinergym.utils.wrappers:LoggerWrapper:
    storage_class: sinergym.utils.logger.LoggerStorage
  sinergym.utils.wrappers:CSVLogger: {}
  sinergym.utils.wrappers:WandBLogger:
    entity: alejandro-campoy
    project_name: test-project

# --------------------------- INITIAL STATE (MODEL) -------------------------- #
# Model from scratch:
model: null

# Local Path:
# model: 
#   local_path: </path/to/model>
# load model normalization if needed
#   normalization:
#     mean: Sinergym_output/evaluation/mean.txt
#     var: Sinergym_output/evaluation/var.txt

# Google Bucket Path:
# model: 
#   bucket_path: gs://<path_to_model_google_bucket>
# load model normalization if needed
#   normalization:
#     mean: <<path_to_model_google_bucket_mean.txt>
#     var: <<path_to_model_google_bucket_var.txt>

# WANDB model path:
# model:
#   project: test-project
#   entity: sail_ugr
#   artifact_name: PPO-Eplus-5zone-hot-continuous-stochastic-v1-episodes-5-id-PPOExperimentExample_2025-02-02_18-31_9jau51uy
#   artifact_type: output
#   artifact_tag: v0
#   artifact_path: Sinergym_output/evaluation/
#   model_path: Sinergym_output/evaluation/best_model.zip
#   # load model normalization if needed
#   normalization:
#     mean: Sinergym_output/evaluation/mean.txt
#     var: Sinergym_output/evaluation/var.txt

# -------------------------- GOOGLE CLOUD (OPTIONAL) ------------------------- #
cloud: 
  remote_store: null # remote bucket name
  auto_delete: null # Delete remote instance when finish experiment
  # auto_delete:
  #   group_name: group-example
